{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create word embeddings from small error messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'utils.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/08/05 13:09:27 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error\n",
      "Found 22 items\n",
      "-rw-r--r--   3 llayer zh   81467745 2019-05-08 17:46 hdfs:///cms/users/llayer/actionhist.csv\n",
      "-rw-r--r--   3 llayer zh   34737856 2019-05-08 16:47 hdfs:///cms/users/llayer/actionshist.h5\n",
      "-rw-r--r--   3 llayer zh   20926756 2019-03-06 14:07 hdfs:///cms/users/llayer/actionshistory.json\n",
      "drwxr-xr-x   - llayer zh          0 2019-05-19 18:47 hdfs:///cms/users/llayer/debug0.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-05-20 16:48 hdfs:///cms/users/llayer/debug1.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-05-20 19:05 hdfs:///cms/users/llayer/debug2.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-05-20 19:09 hdfs:///cms/users/llayer/debug3.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-05-20 19:23 hdfs:///cms/users/llayer/debug4.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-05-20 19:35 hdfs:///cms/users/llayer/debug5.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-05-20 18:30 hdfs:///cms/users/llayer/df_reduced_codes.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-05-20 18:47 hdfs:///cms/users/llayer/df_reduced_codes2.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-03-06 15:42 hdfs:///cms/users/llayer/example.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-04-25 00:25 hdfs:///cms/users/llayer/fail_test.csv\n",
      "-rw-r--r--   3 llayer zh        252 2019-03-06 15:27 hdfs:///cms/users/llayer/failing_log_0.spec\n",
      "-rw-r--r--   3 llayer zh    4159974 2019-03-08 15:49 hdfs:///cms/users/llayer/failing_tasks.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-08-04 19:08 hdfs:///cms/users/llayer/single_writeout_010117_101117.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-08-04 17:53 hdfs:///cms/users/llayer/single_writeout_020710_080119.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-08-04 18:10 hdfs:///cms/users/llayer/single_writeout_060118_020719.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-08-04 18:25 hdfs:///cms/users/llayer/single_writeout_101117_060118.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-08-04 17:10 hdfs:///cms/users/llayer/test_full_writeout.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-05-12 19:58 hdfs:///cms/users/llayer/test_word2vec.csv\n",
      "drwxr-xr-x   - llayer zh          0 2019-05-13 17:27 hdfs:///cms/users/llayer/test_word2vec2.csv\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls hdfs:///cms/users/llayer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted hdfs:///cms/users/llayer/output.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm -r -skipTrash hdfs:///cms/users/llayer/output*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data from HDFS with the WMArchive entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timerange = [20180706, 20180706]\n",
    "#timerange = [20171011, 20190401]\n",
    "#timerange = [20190207, 20190801]\n",
    "#timerange = [20180601, 20190207]\n",
    "#timerange = [20171011, 20180601]\n",
    "#timerange = [20180704, 20181004]  # for test task '/pdmvserv_task_HIG-RunIIFall17wmLHEGS-02145__v1_T_180705_162228_8813/HIG-RunIIFall17wmLHEGS-02145_0/HIG-RunIIFall17DRPremix-02708_0'\n",
    "timerange = [20170101, 20171009]\n",
    "dirs = ut.getDirs( timerange )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hdfs:///cms/wmarchive/avro/fwjr/2017/01/01', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/02', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/03', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/04', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/05', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/06', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/07', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/08', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/09', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/10', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/11', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/12', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/13', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/14', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/15', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/16', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/17', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/18', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/19', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/20', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/21', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/22', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/23', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/24', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/25', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/26', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/27', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/28', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/29', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/30', 'hdfs:///cms/wmarchive/avro/fwjr/2017/01/31', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/01', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/02', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/03', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/04', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/07', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/08', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/09', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/10', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/11', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/12', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/13', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/14', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/15', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/16', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/17', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/18', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/19', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/20', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/21', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/22', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/23', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/24', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/25', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/26', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/27', 'hdfs:///cms/wmarchive/avro/fwjr/2017/02/28', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/01', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/02', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/03', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/04', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/05', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/06', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/07', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/08', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/09', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/10', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/11', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/12', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/13', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/14', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/15', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/16', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/17', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/18', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/19', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/20', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/21', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/22', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/23', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/24', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/25', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/26', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/27', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/28', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/29', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/30', 'hdfs:///cms/wmarchive/avro/fwjr/2017/03/31', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/01', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/02', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/03', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/04', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/05', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/06', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/07', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/08', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/09', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/10', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/11', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/12', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/13', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/14', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/15', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/16', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/17', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/18', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/19', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/20', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/21', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/22', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/23', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/24', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/25', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/26', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/27', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/28', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/29', 'hdfs:///cms/wmarchive/avro/fwjr/2017/04/30', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/01', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/02', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/03', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/04', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/05', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/06', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/07', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/08', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/09', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/10', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/11', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/12', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/13', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/14', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/15', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/16', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/17', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/18', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/19', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/23', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/24', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/25', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/26', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/27', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/28', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/29', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/30', 'hdfs:///cms/wmarchive/avro/fwjr/2017/05/31', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/01', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/02', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/03', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/04', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/05', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/06', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/07', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/08', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/09', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/10', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/11', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/12', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/13', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/14', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/15', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/16', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/17', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/18', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/19', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/20', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/21', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/23', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/24', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/25', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/26', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/27', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/28', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/29', 'hdfs:///cms/wmarchive/avro/fwjr/2017/06/30', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/06', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/07', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/08', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/09', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/10', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/11', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/12', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/13', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/14', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/15', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/16', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/17', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/18', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/19', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/20', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/21', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/22', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/23', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/24', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/25', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/26', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/27', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/28', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/29', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/30', 'hdfs:///cms/wmarchive/avro/fwjr/2017/07/31', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/01', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/02', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/03', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/04', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/05', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/06', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/07', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/08', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/09', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/10', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/11', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/12', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/13', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/14', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/15', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/16', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/17', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/18', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/19', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/20', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/21', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/22', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/23', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/24', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/25', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/26', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/27', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/28', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/29', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/30', 'hdfs:///cms/wmarchive/avro/fwjr/2017/08/31', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/01', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/02', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/03', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/04', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/05', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/07', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/08', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/09', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/10', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/11', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/12', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/13', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/14', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/15', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/16', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/17', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/18', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/19', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/20', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/21', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/22', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/23', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/24', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/25', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/26', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/27', 'hdfs:///cms/wmarchive/avro/fwjr/2017/09/28', 'hdfs:///cms/wmarchive/avro/fwjr/2017/10/03', 'hdfs:///cms/wmarchive/avro/fwjr/2017/10/04', 'hdfs:///cms/wmarchive/avro/fwjr/2017/10/05', 'hdfs:///cms/wmarchive/avro/fwjr/2017/10/06', 'hdfs:///cms/wmarchive/avro/fwjr/2017/10/07', 'hdfs:///cms/wmarchive/avro/fwjr/2017/10/09']\n"
     ]
    }
   ],
   "source": [
    "print dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema_file = 'hdfs:///cms/wmarchive/avro/schema.avsc'\n",
    "schema_file = 'hdfs:///cms/wmarchive/avro/schemas/current.avsc.20161215'\n",
    "rdd = sc.textFile(schema_file, 1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input avro schema, the rdd is a list of lines (sc.textFile similar to readlines)\n",
    "avsc = reduce(lambda x, y: x + y, rdd) # merge all entries from rdd list\n",
    "schema = ''.join(avsc.split()) # remove spaces in avsc map\n",
    "conf = {\"avro.schema.input.key\": schema}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define newAPIHadoopFile parameters, java classes\n",
    "aformat=\"org.apache.avro.mapreduce.AvroKeyInputFormat\"\n",
    "akey=\"org.apache.avro.mapred.AvroKey\"\n",
    "awrite=\"org.apache.hadoop.io.NullWritable\"\n",
    "aconv=\"org.apache.spark.examples.pythonconverters.AvroWrapperToJavaConverter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = dirs\n",
    "# load data from HDFS\n",
    "if  isinstance(data_path, list):\n",
    "    avro_rdd = sc.union([sc.newAPIHadoopFile(f, aformat, akey, awrite, aconv, conf=conf) for f in data_path])\n",
    "else:\n",
    "    avro_rdd = sc.newAPIHadoopFile(data_path, aformat, akey, awrite, aconv, conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter out the failing tasks and create a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the tasks - keep only failing \n",
    "def getFailing(row):\n",
    "    rec = row[0]\n",
    "    meta = rec.get('meta_data', {})\n",
    "    if meta.get('jobstate', '') != 'jobfailed':\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# create task, site, error key  \n",
    "def avro_rdd_KV(row):\n",
    "    rec = row[0]\n",
    "    task = rec[\"task\"]\n",
    "    steps = rec.get('steps', [])\n",
    "    exit_code = []\n",
    "    site = []\n",
    "    error_msg = []\n",
    "    error_type = []\n",
    "    \n",
    "    \n",
    "    for step in steps:\n",
    "        errors = step['errors']\n",
    "        #details = []\n",
    "        #exitCodes = []\n",
    "        for error in errors:\n",
    "            #details.append(error['details'])\n",
    "            #exitCodes.append(error['exitCode'])\n",
    "            exit_code.append(error['exitCode'])\n",
    "            error_type.append(error['type'])\n",
    "            error_msg.append( error['details'].replace(\"\\n\", \" \").replace('\\r', ' ') )\n",
    "            site.append( step.get('site','') )\n",
    "    \n",
    "    return [(task, site, error, error_type, msg) for error, msg, site, error_type in zip(exit_code, error_msg, site, error_type) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data\n",
    "failing_workflows = avro_rdd.filter(lambda x : getFailing(x)).flatMap(lambda x : avro_rdd_KV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "failing_workflows_df_test = failing_workflows.toDF([\"task_name\", \"site\", \"error\", \"error_msg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----+--------------------+\n",
      "|           task_name|site|error|           error_msg|\n",
      "+--------------------+----+-----+--------------------+\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_BT...|null|99303|Could not find jo...|\n",
      "+--------------------+----+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "failing_workflows_df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_KV(row):\n",
    "    \n",
    "    # Assume that the first error code per step is the correct one\n",
    "    rec = row[0]\n",
    "    task = rec[\"task\"]\n",
    "    steps = rec.get('steps', [])\n",
    "    \n",
    "    exit_code_first = []\n",
    "    sites_first = []\n",
    "    exit_codes = []\n",
    "    error_msg = []\n",
    "    error_type = []\n",
    "    steps = []\n",
    "    names = []\n",
    "    peakvaluerss = []\n",
    "    peakvaluevsize = []\n",
    "    writeTotalMB = []\n",
    "    readPercentageOps = []\n",
    "    readAveragekB = []\n",
    "    readTotalMB = []\n",
    "    readNumOps = []\n",
    "    readCachePercentageOps = []\n",
    "    readMBSec = []\n",
    "    writeTotalSecs = []\n",
    "    readTotalSecs = []\n",
    "    readMaxMSec = []\n",
    "    TotalJobCPU = []\n",
    "    NumberOfStreams = []\n",
    "    TotalInitCPU = []\n",
    "    TotalEventCPU = []\n",
    "    AvgEventCPU = []\n",
    "    EventThroughput = []\n",
    "    TotalInitTime = []\n",
    "    AvgEventTime = []\n",
    "    NumberOfThreads = []\n",
    "    MinEventCPU = []\n",
    "    MaxEventTime = []\n",
    "    TotalJobTime = []\n",
    "    TotalLoopCPU = []\n",
    "    MinEventTime = []\n",
    "    MaxEventCPU = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for counter, step in enumerate(steps):\n",
    "        errors = step['errors']\n",
    "        \n",
    "        if len(errors) > 0:\n",
    "            # Save the first exit code per step\n",
    "            exit_code_first.append(errors[0]['exitCode'])\n",
    "            # Save the site\n",
    "            sites_first.append( step.get('site','') )\n",
    "            # Save the step number\n",
    "            #steps.append(counter)\n",
    "            # Save the name\n",
    "            #names.append( step.get('name', '') )\n",
    "            \"\"\"\n",
    "            # Save memory\n",
    "            peakvaluerss.append( errors['performance']['memory']['PeakValueRss'] )\n",
    "            peakvaluevsize.append( errors['performance']['memory']['PeakValueVsize'] )\n",
    "            # Save storage\n",
    "            writeTotalMB.append(errors['performance']['storage']['writeTotalMB'])\n",
    "            readPercentageOps.append(errors['performance']['storage']['readPercentageOps'])\n",
    "            readAveragekB.append(errors['performance']['storage']['readAveragekB'])\n",
    "            readTotalMB.append(errors['performance']['storage']['readTotalMB'])\n",
    "            readNumOps.append(errors['performance']['storage']['readNumOps'])\n",
    "            readCachePercentageOps.append(errors['performance']['storage']['readCachePercentageOps'])\n",
    "            readMBSec.append(errors['performance']['storage']['readMBSec'])\n",
    "            writeTotalSecs.append(errors['performance']['storage']['writeTotalSecs'])\n",
    "            readTotalSecs.append(errors['performance']['storage']['readTotalSecs'])\n",
    "            readMaxMSec.append(errors['performance']['storage']['readMaxMSec'])\n",
    "            # Save CPU\n",
    "            TotalJobCPU.append(errors['performance']['cpu']['TotalJobCPU'])\n",
    "            NumberOfStreams.append(errors['performance']['cpu']['NumberOfStreams'])\n",
    "            TotalInitCPU.append(errors['performance']['cpu']['TotalInitCPU'])\n",
    "            TotalEventCPU.append(errors['performance']['cpu']['TotalEventCPU'])\n",
    "            AvgEventCPU.append(errors['performance']['cpu']['AvgEventCPU'])\n",
    "            EventThroughput.append(errors['performance']['cpu']['EventThroughput'])\n",
    "            TotalInitTime.append(errors['performance']['cpu']['TotalInitTime'])\n",
    "            AvgEventTime.append(errors['performance']['cpu']['AvgEventTime'])\n",
    "            NumberOfThreads.append(errors['performance']['cpu']['NumberOfThreads'])\n",
    "            MinEventCPU.append(errors['performance']['cpu']['MinEventCPU'])\n",
    "            MaxEventTime.append(errors['performance']['cpu']['MaxEventTime'])\n",
    "            TotalJobTime.append(errors['performance']['cpu']['TotalJobTime'])\n",
    "            TotalLoopCPU.append(errors['performance']['cpu']['TotalLoopCPU'])\n",
    "            MinEventTime.append(errors['performance']['cpu']['MinEventTime'])\n",
    "            MaxEventCPU.append(errors['performance']['cpu']['MaxEventCPU'])            \n",
    "            \"\"\"\n",
    "            \n",
    "            # Loop over the errors\n",
    "            for error in errors:\n",
    "                                   \n",
    "                exit_codes.append(error['exitCode'])\n",
    "                error_type.append( error['type'] )\n",
    "                error_msg.append( error['details'] )\n",
    "                \n",
    "    #return [(\"{0}{1}{2}\".format(task, exit_code, site), (task, exit_code, site)) for exit_code, site in zip(exit_code_first, site_first)]\n",
    "    return  [(task, site, exit_code) for site, exit_code in zip(sites_first, exit_code_first) ]\n",
    "    #return [((task, e, s), rec) for e, s in zip(exit_code_first, sites)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Filter the error chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_KV(row):\n",
    "    \n",
    "    # Assume that the first error code per step is the correct one\n",
    "    rec = row[0]\n",
    "    task = rec[\"task\"]\n",
    "    steps = rec.get('steps', [])\n",
    "    \n",
    "    exit_code_first = []\n",
    "    sites = []\n",
    "    exit_codes = []\n",
    "    error_msg = []\n",
    "    error_type = []\n",
    "    steps_counter = []\n",
    "    names = []\n",
    "    peakvaluerss = []\n",
    "    peakvaluevsize = []\n",
    "    writeTotalMB = []\n",
    "    readPercentageOps = []\n",
    "    readAveragekB = []\n",
    "    readTotalMB = []\n",
    "    readNumOps = []\n",
    "    readCachePercentageOps = []\n",
    "    readMBSec = []\n",
    "    writeTotalSecs = []\n",
    "    readTotalSecs = []\n",
    "    readMaxMSec = []\n",
    "    TotalJobCPU = []\n",
    "    NumberOfStreams = []\n",
    "    TotalInitCPU = []\n",
    "    TotalEventCPU = []\n",
    "    AvgEventCPU = []\n",
    "    EventThroughput = []\n",
    "    TotalInitTime = []\n",
    "    AvgEventTime = []\n",
    "    NumberOfThreads = []\n",
    "    MinEventCPU = []\n",
    "    MaxEventTime = []\n",
    "    TotalJobTime = []\n",
    "    TotalLoopCPU = []\n",
    "    MinEventTime = []\n",
    "    MaxEventCPU = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for counter, step in enumerate(steps):\n",
    "        errors = step['errors']\n",
    "        \n",
    "        if len(errors) > 0:\n",
    "            # Save the first exit code per step\n",
    "            exit_code_first.append(errors[0]['exitCode'])\n",
    "            # Save the site\n",
    "            sites.append( step.get('site','') )\n",
    "            # Save the step number\n",
    "            #steps.append(counter)\n",
    "            # Save the name\n",
    "            #names.append( step.get('name', '') )\n",
    "            \n",
    "            # Loop over the errors\n",
    "            for error in errors:\n",
    "                                   \n",
    "                exit_codes.append(error['exitCode'])\n",
    "                steps_counter.append(counter)\n",
    "                names.append( step.get('name', '') )\n",
    "                error_type.append( error['type'] )\n",
    "                error_msg.append( error['details'].replace(\"\\n\", \" \").replace('\\r', ' ') )\n",
    "                \n",
    "                \n",
    "                # Save memory\n",
    "                for k,v in step['performance']['memory'].iteritems():\n",
    "                    \n",
    "                    value = -1. if v is None else v\n",
    "                    if k == 'PeakValueVsize':\n",
    "                        peakvaluevsize.append(value)\n",
    "                    if k == 'PeakValueRss':\n",
    "                        peakvaluerss.append(value)\n",
    "                \n",
    "                # Save storage\n",
    "                for k,v in step['performance']['storage'].iteritems():\n",
    "                    \n",
    "                    value = -1. if v is None else v\n",
    "                    if k == 'writeTotalMB':\n",
    "                        writeTotalMB.append(value)\n",
    "                    if k == 'readPercentageOps':\n",
    "                        readPercentageOps.append(value)                        \n",
    "                    if k == 'readAveragekB':\n",
    "                        readAveragekB.append(value)\n",
    "                    if k == 'readTotalMB':\n",
    "                        readTotalMB.append(value)                     \n",
    "                    if k == 'readNumOps':\n",
    "                        readNumOps.append(value)\n",
    "                    if k == 'readCachePercentageOps':\n",
    "                        readCachePercentageOps.append(value)                        \n",
    "                    if k == 'writeTotalSecs':\n",
    "                        writeTotalSecs.append(value)\n",
    "                    if k == 'readMBSec':\n",
    "                        readMBSec.append(value)                  \n",
    "                    if k == 'readTotalSecs':\n",
    "                        readTotalSecs.append(value)\n",
    "                    if k == 'readMaxMSec':\n",
    "                        readMaxMSec.append(value)                  \n",
    "\n",
    "                # Save cpu\n",
    "                for k,v in step['performance']['cpu'].iteritems():\n",
    "                    \n",
    "                    value = -1. if v is None else v\n",
    "                    if k == 'TotalJobCPU':\n",
    "                        TotalJobCPU.append(value)\n",
    "                    if k == 'NumberOfStreams':\n",
    "                        NumberOfStreams.append(value)  \n",
    "                    if k == 'TotalInitCPU':\n",
    "                        TotalInitCPU.append(value)\n",
    "                    if k == 'TotalEventCPU':\n",
    "                        TotalEventCPU.append(value)                 \n",
    "                    if k == 'AvgEventCPU':\n",
    "                        AvgEventCPU.append(value)\n",
    "                    if k == 'EventThroughput':\n",
    "                        EventThroughput.append(value)  \n",
    "                    if k == 'TotalInitTime':\n",
    "                        TotalInitTime.append(value)\n",
    "                    if k == 'AvgEventTime':\n",
    "                        AvgEventTime.append(value)                  \n",
    "                    if k == 'NumberOfThreads':\n",
    "                        NumberOfThreads.append(value)\n",
    "                    if k == 'MinEventCPU':\n",
    "                        MinEventCPU.append(value)  \n",
    "                    if k == 'MaxEventTime':\n",
    "                        MaxEventTime.append(value)\n",
    "                    if k == 'TotalJobTime':\n",
    "                        TotalJobTime.append(value)\n",
    "                    if k == 'TotalLoopCPU':\n",
    "                        TotalLoopCPU.append(value)  \n",
    "                    if k == 'MinEventTime':\n",
    "                        MinEventTime.append(value)\n",
    "                    if k == 'MaxEventCPU':\n",
    "                        MaxEventCPU.append(value)          \n",
    "                        \n",
    "                        \n",
    "    # Hack for the 2017 schema\n",
    "    if len(NumberOfStreams) == 0:\n",
    "        for i in range(len(AvgEventCPU)):\n",
    "            NumberOfStreams.append(-1.)\n",
    "            TotalInitCPU.append(-1.) \n",
    "            TotalInitTime.append(-1.) \n",
    "            NumberOfThreads.append(-1.)\n",
    "    \n",
    "    res = (exit_codes, error_msg, error_type, steps_counter, names, peakvaluerss, peakvaluevsize, writeTotalMB, readPercentageOps, readAveragekB, readTotalMB,\\\n",
    "            readNumOps, readCachePercentageOps, readMBSec, writeTotalSecs, readTotalSecs, readMaxMSec, \n",
    "            TotalJobCPU, NumberOfStreams, TotalInitCPU, TotalEventCPU, AvgEventCPU, EventThroughput, \n",
    "            TotalInitTime, AvgEventTime, NumberOfThreads, MinEventCPU, MaxEventTime, TotalJobTime,\n",
    "            TotalLoopCPU, MinEventTime,MaxEventCPU)\n",
    "        \n",
    "    #return [(\"{0}{1}{2}\".format(task, exit_code, site), (task, exit_code, site)) for exit_code, site in zip(exit_code_first, site_first)]\n",
    "    #return  [(task, site, exit_code) for site, exit_code in zip(sites_first, exit_code_first) ]\n",
    "    return [((task, e, s), res) for e, s in zip(exit_code_first, sites)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = avro_rdd.filter(lambda x : getFailing(x)).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'TotalJobCPU', u'TotalEventCPU', u'AvgEventCPU', u'EventThroughput', u'AvgEventTime', u'MinEventCPU', u'MaxEventTime', u'TotalJobTime', u'TotalLoopCPU', u'MinEventTime', u'MaxEventCPU']\n"
     ]
    }
   ],
   "source": [
    "print list(test[0][0]['steps'][0]['performance']['cpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data\n",
    "failing_workflows = avro_rdd.filter(lambda x : getFailing(x)).flatMap(lambda x : map_to_KV(x))\n",
    "#failing_workflows = avro_rdd.filter(lambda x : getFailing(x)).flatMap(lambda x : map_to_KV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((u'/pdmvserv_task_SMP-RunIISummer16DR80Premix-00011__v1_T_161227_083845_4347/SMP-RunIISummer16DR80Premix-00011_0', 99999, u'T2_UK_London_IC'), ([99999, 137, 50115, 99999], [u'Could not find report file for step stageOut1!', u\"  Adding last 25 lines of CMSSW stdout:  Too many Tau (8) for uGT Configuration maxTau =8 %MSG %MSG-w L1TGlobal:  L1TGlobalProducer:simGtStage2Digis 01-Jan-2017 00:43:12 GMT  Run: 1 Event: 3136598  Too many Tau (9) for uGT Configuration maxTau =8 %MSG %MSG-w L1TGlobal:  L1TGlobalProducer:simGtStage2Digis 01-Jan-2017 00:43:12 GMT  Run: 1 Event: 3136598  Too many Tau (10) for uGT Configuration maxTau =8 %MSG %MSG-w L1TGlobal:  L1TGlobalProducer:simGtStage2Digis 01-Jan-2017 00:43:12 GMT  Run: 1 Event: 3136598  Too many Tau (11) for uGT Configuration maxTau =8 %MSG %MSG-w L1TGlobal:  L1TGlobalProducer:hltGtStage2ObjectMap  01-Jan-2017 00:43:12 GMT Run: 1 Event: 3136598  Too many Tau (8) for uGT Configuration maxTau =8 %MSG %MSG-w L1TGlobal:  L1TGlobalProducer:hltGtStage2ObjectMap  01-Jan-2017 00:43:12 GMT Run: 1 Event: 3136598  Too many Tau (9) for uGT Configuration maxTau =8 %MSG %MSG-w L1TGlobal:  L1TGlobalProducer:hltGtStage2ObjectMap  01-Jan-2017 00:43:12 GMT Run: 1 Event: 3136598  Too many Tau (10) for uGT Configuration maxTau =8 %MSG %MSG-w L1TGlobal:  L1TGlobalProducer:hltGtStage2ObjectMap  01-Jan-2017 00:43:12 GMT Run: 1 Event: 3136598  Too many Tau (11) for uGT Configuration maxTau =8 %MSG Complete process id is 21109 status is 137 CmsRunFailure Message: Error running cmsRun {'arguments': ['/bin/bash', '/srv/localstage/scratch/927592.1.grid.q/gFeNDmYf8gpn3dFDVpGiSQRqaTsoMnABFKDmhDMKDmOBFKDmIo64fm/glide_EPGqF1/execute/dir_19078/job/WMTaskSpace/cmsRun1/cmsRun1-main.sh', '', 'slc6_amd64_gcc530', 'scramv1', 'CMSSW', 'CMSSW_8_0_21', 'FrameworkJobReport.xml', 'cmsRun', 'PSet.py', '', '', '']} Return code: 137  \\tModuleName : WMCore.WMSpec.Steps.WMExecutionFailure \\tMethodName : __init__ \\tClassInstance : None \\tFileName : /srv/localstage/scratch/927592.1.grid.q/gFeNDmYf8gpn3dFDVpGiSQRqaTsoMnABFKDmhDMKDmOBFKDmIo64fm/glide_EPGqF1/execute/dir_19078/job/WMCore.zip/WMCore/WMSpec/Steps/WMExecutionFailure.py \\tClassName : None \\tLineNumber : 18 \\tErrorNr : 137  Traceback:   \", u'Error reading XML job report file, possibly corrupt XML File: Details: no element found: line 278, column 0', u'Adding extra error in order to hold error report  Adding last ten lines of CMSSW stderr: WARNING: In non-interactive mode release checks e.g. deprecated releases, production architectures are disabled. WARNING: There already exists /srv/localstage/scratch/927592.1.grid.q/gFeNDmYf8gpn3dFDVpGiSQRqaTsoMnABFKDmhDMKDmOBFKDmIo64fm/glide_EPGqF1/execute/dir_19078/job/WMTaskSpace/cmsRun1/CMSSW_8_0_21 area for SCRAM_ARCH slc6_amd64_gcc530. /srv/localstage/scratch/927592.1.grid.q/gFeNDmYf8gpn3dFDVpGiSQRqaTsoMnABFKDmhDMKDmOBFKDmIo64fm/glide_EPGqF1/execute/dir_19078/job/WMTaskSpace/cmsRun1/cmsRun1-main.sh: line 78: 21109 Killed                  $EXECUTABLE -j $JOB_REPORT $CONFIGURATION 2>&1 '], [u'ReportManipulatingError', u'CMSSWStepFailure', u'BadFWJRXML', u'ErrorLoggingAddition'], [0, 2, 2, 2], [u'stageOut1', u'cmsRun1', u'cmsRun1', u'cmsRun1'], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0], [-1.0, -1.0, -1.0, -1.0]))]\n"
     ]
    }
   ],
   "source": [
    "print failing_workflows.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failing_workflows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(x):\n",
    "    return \"{0}{1}{2}\".format(x[0], x[1], x[2])\n",
    "m = failing_workflows.map(lambda x: (get_key(x),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce redundant keys\n",
    "r = failing_workflows.reduceByKey(lambda x,y: (x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'/pdmvserv_task_B2G-RunIISummer16DR80Premix-01169__v1_T_161227_164426_7583/B2G-RunIISummer16DR80Premix-01169_0/B2G-RunIISummer16DR80Premix-01169_1/B2G-RunIISummer16DR80Premix-01169_1MergeAODSIMoutput',\n",
       "   99999,\n",
       "   u'T2_FR_GRIF_LLR'),\n",
       "  ([99999, 139, 50115, 99999],\n",
       "   [u'Could not find report file for step stageOut1!',\n",
       "    u\"  Adding last 25 lines of CMSSW stdout: #16 0x00002af28c0f88e6 in XrdAdaptor::RequestManager::handle(std::shared_ptr<XrdAdaptor::ClientRequest>) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libUtilitiesXrdAdaptor.so #17 0x00002af28c0d0c8f in XrdFile::read(void*, unsigned long) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libUtilitiesXrdAdaptor.so #18 0x00002af27f42db46 in StorageAccountProxy::read(void*, unsigned long) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libUtilitiesStorageFactory.so #19 0x00002af27f44ddb5 in IOInput::xread(void*, unsigned long) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libUtilitiesStorageFactory.so #20 0x00002af27fd2f1ee in TStorageFactoryFile::ReadBuffer(char*, int) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libIOPoolTFileAdaptor.so #21 0x00002af27cb63144 in TBasket::LoadBasketBuffers(long long, int, TFile*, TTree*) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/external/slc6_amd64_gcc530/lib/libTree.so #22 0x00002af27cb32b08 in TTreeCloner::WriteBaskets() () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/external/slc6_amd64_gcc530/lib/libTree.so #23 0x00002af27cb331a7 in TTreeCloner::Exec() () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/external/slc6_amd64_gcc530/lib/libTree.so #24 0x00002af2a662722a in edm::RootOutputTree::fastCloneTTree(TTree*, std::string const&) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libIOPoolOutput.so #25 0x00002af2a6627857 in edm::RootOutputTree::maybeFastCloneTree(bool, bool, TTree*, std::string const&) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libIOPoolOutput.so #26 0x00002af2a661de1c in edm::RootOutputFile::beginInputFile(edm::FileBlock const&, int) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libIOPoolOutput.so #27 0x00002af27c5bddff in edm::Schedule::respondToOpenInputFile(edm::FileBlock const&) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libFWCoreFramework.so #28 0x00002af27c59cbd0 in edm::EventProcessor::respondToOpenInputFile() () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libFWCoreFramework.so #29 0x00002af27c510908 in statemachine::HandleNewInputFile3::HandleNewInputFile3(boost::statechart::state<statemachine::HandleNewInputFile3, statemachine::HandleLumis, boost::mpl::list<mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na>, (boost::statechart::history_mode)0>::my_context) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libFWCoreFramework.so #30 0x00002af27c515fde in boost::statechart::state<statemachine::HandleNewInputFile3, statemachine::HandleLumis, boost::mpl::list<mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na>, (boost::statechart::history_mode)0>::shallow_construct(boost::intrusive_ptr<statemachine::HandleLumis> const&, boost::statechart::state_machine<statemachine::Machine, statemachine::Starting, std::allocator<void>, boost::statechart::null_exception_translator>&) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libFWCoreFramework.so #31 0x00002af27c5124a6 in statemachine::HandleEvent::react(statemachine::File const&) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libFWCoreFramework.so #32 0x00002af27c518dc8 in boost::statechart::simple_state<statemachine::HandleEvent, statemachine::HandleLumis, boost::mpl::list<mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na, mpl_::na>, (boost::statechart::history_mode)0>::react_impl(boost::statechart::event_base const&, void const*) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libFWCoreFramework.so #33 0x00002af27c5b0f48 in boost::statechart::state_machine<statemachine::Machine, statemachine::Starting, std::allocator<void>, boost::statechart::null_exception_translator>::process_event(boost::statechart::event_base const&) () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libFWCoreFramework.so #34 0x00002af27c5a1a87 in edm::EventProcessor::runToCompletion() () from /cvmfs/cms.cern.ch/slc6_amd64_gcc530/cms/cmssw/CMSSW_8_0_21/lib/slc6_amd64_gcc530/libFWCoreFramework.so #35 0x000000000040c763 in main::{lambda()#1}::operator()() const () #36 0x000000000040ac36 in main ()  A fatal system signal has occurred: segmentation violation Complete process id is 3725666 status is 139 CmsRunFailure Message: Error running cmsRun {'arguments': ['/bin/bash', '/var/lib/condor/execute/dir_3550895/glide_sp8KgZ/execute/dir_3725005/job/WMTaskSpace/cmsRun1/cmsRun1-main.sh', '', 'slc6_amd64_gcc530', 'scramv1', 'CMSSW', 'CMSSW_8_0_21', 'FrameworkJobReport.xml', 'cmsRun', 'PSet.py', '', '', '']} Return code: 139  \\tModuleName : None \\tMethodName : __init__ \\tClassInstance : None \\tFileName : /data/srv/wmagent/v1.0.21.patch3/sw/slc6_amd64_gcc493/cms/wmagent/1.0.21.patch3/lib/python2.7/site-packages/WMCore/WMSpec/Steps/WMExecutionFailure.py \\tClassName : None \\tLineNumber : 18 \\tErrorNr : 139  Traceback:   \",\n",
       "    u'Error reading XML job report file, possibly corrupt XML File: Details: no element found: line 896, column 0',\n",
       "    u'Adding extra error in order to hold error report  Adding last ten lines of CMSSW stderr: WARNING: In non-interactive mode release checks e.g. deprecated releases, production architectures are disabled. WARNING: There already exists /var/lib/condor/execute/dir_3550895/glide_sp8KgZ/execute/dir_3725005/job/WMTaskSpace/cmsRun1/CMSSW_8_0_21 area for SCRAM_ARCH slc6_amd64_gcc530. /var/lib/condor/execute/dir_3550895/glide_sp8KgZ/execute/dir_3725005/job/WMTaskSpace/cmsRun1/cmsRun1-main.sh: line 78: 3725666 Segmentation fault      $EXECUTABLE -j $JOB_REPORT $CONFIGURATION 2>&1 '],\n",
       "   [u'ReportManipulatingError',\n",
       "    u'CMSSWStepFailure',\n",
       "    u'BadFWJRXML',\n",
       "    u'ErrorLoggingAddition'],\n",
       "   [0, 2, 2, 2],\n",
       "   [u'stageOut1', u'cmsRun1', u'cmsRun1', u'cmsRun1'],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0],\n",
       "   [-1.0, -1.0, -1.0, -1.0]))]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_frame_format(row):\n",
    "    keys = row[0]\n",
    "    rec = row[1]\n",
    "    \n",
    "    variables = zip(*rec)\n",
    "    \n",
    "    return [keys + var for var in variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r.flatMap(lambda x: map_to_frame_format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = r2.toDF([\"task_name\", \"error\", \"site\", \"exit_codes\", \"error_msg\", \"error_type\", \"steps_counter\", \"names\",\"peakvaluerss\", \"peakvaluevsize\" , \"writeTotalMB\", \"readPercentageOps\", \"readAveragekB\", \"readTotalMB\",\\\n",
    "\"readNumOps\", \"readCachePercentageOps\", \"readMBSec\", \"writeTotalSecs\", \"readTotalSecs\", \"readMaxMSec\", \n",
    "\"TotalJobCPU\", \"NumberOfStreams\", \"TotalInitCPU\", \"TotalEventCPU\", \"AvgEventCPU\", \"EventThroughput\", \n",
    "\"TotalInitTime\", \"AvgEventTime\", \"NumberOfThreads\", \"MinEventCPU\", \"MaxEventTime\", \"TotalJobTime\",\n",
    "\"TotalLoopCPU\", \"MinEventTime\", \"MaxEventCPU\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+---------------+----------+--------------------+--------------------+-------------+---------+------------+--------------+------------+------------------+-----------------+-----------+----------+----------------------+------------------+--------------+-------------+-----------+-----------+---------------+------------+-------------+-----------+---------------+-------------+------------+---------------+-----------+------------+------------+------------+------------+-----------+\n",
      "|           task_name|error|           site|exit_codes|           error_msg|          error_type|steps_counter|    names|peakvaluerss|peakvaluevsize|writeTotalMB| readPercentageOps|    readAveragekB|readTotalMB|readNumOps|readCachePercentageOps|         readMBSec|writeTotalSecs|readTotalSecs|readMaxMSec|TotalJobCPU|NumberOfStreams|TotalInitCPU|TotalEventCPU|AvgEventCPU|EventThroughput|TotalInitTime|AvgEventTime|NumberOfThreads|MinEventCPU|MaxEventTime|TotalJobTime|TotalLoopCPU|MinEventTime|MaxEventCPU|\n",
      "+--------------------+-----+---------------+----------+--------------------+--------------------+-------------+---------+------------+--------------+------------+------------------+-----------------+-----------+----------+----------------------+------------------+--------------+-------------+-----------+-----------+---------------+------------+-------------+-----------+---------------+-------------+------------+---------------+-----------+------------+------------+------------+------------+-----------+\n",
      "|/pdmvserv_task_HI...|60307|      T1_DE_KIT|     99109|Error in StageOut...|Misc. StageOut er...|            0|stageOut1|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/pdmvserv_task_HI...|60307|      T1_DE_KIT|     60307|<@========== WMEx...|   LogArchiveFailure|            1| logArch1|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/vlimant_task_SMP...|   84|   T2_ES_CIEMAT|        84|  Adding last 25 ...|    CMSSWStepFailure|            0|  cmsRun4|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/vlimant_task_SMP...|   84|   T2_ES_CIEMAT|      8020|An exception of c...|     Fatal Exception|            0|  cmsRun4|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/vlimant_task_SMP...|   84|   T2_ES_CIEMAT|     99999|Adding extra erro...|ErrorLoggingAddition|            0|  cmsRun4|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/vlimant_task_SMP...|   84|   T2_ES_CIEMAT|        84|  Adding last 25 ...|    CMSSWStepFailure|            2|  cmsRun3|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/vlimant_task_SMP...|   84|   T2_ES_CIEMAT|      8020|An exception of c...|     Fatal Exception|            2|  cmsRun3|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/vlimant_task_SMP...|   84|   T2_ES_CIEMAT|     99999|Adding extra erro...|ErrorLoggingAddition|            2|  cmsRun3|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/vlimant_task_SMP...|   84|   T2_ES_CIEMAT|       139|  Adding last 25 ...|    CMSSWStepFailure|            3|  cmsRun2|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/vlimant_task_SMP...|   84|   T2_ES_CIEMAT|     99999|Adding extra erro...|ErrorLoggingAddition|            3|  cmsRun2|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/fabozzi_Run2016E...|60307|T1_US_FNAL_Disk|     99109|Error in StageOut...|Misc. StageOut er...|            0|stageOut1|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/fabozzi_Run2016E...|60307|T1_US_FNAL_Disk|     60307|StageOutFailure M...|   LogArchiveFailure|            1| logArch1|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/fabozzi_Run2016D...|  139|  T2_US_Caltech|     99999|Could not find re...|ReportManipulatin...|            0|stageOut1|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/fabozzi_Run2016D...|  139|  T2_US_Caltech|       139|  Adding last 25 ...|    CMSSWStepFailure|            2|  cmsRun1|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/fabozzi_Run2016D...|  139|  T2_US_Caltech|     50115|Error reading XML...|          BadFWJRXML|            2|  cmsRun1|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/fabozzi_Run2016D...|  139|  T2_US_Caltech|     99999|Adding extra erro...|ErrorLoggingAddition|            2|  cmsRun1|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/pdmvserv_task_HI...|11003|     T2_FR_IPHC|     11003|Failed to extract...|  JobExtractionError|            0| CRITICAL|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/pdmvserv_task_HI...|   85|   T2_US_Purdue|     99999|Could not find re...|ReportManipulatin...|            0|stageOut1|        -1.0|          -1.0|        -1.0|              -1.0|             -1.0|       -1.0|      -1.0|                  -1.0|              -1.0|          -1.0|         -1.0|       -1.0|       -1.0|           -1.0|        -1.0|         -1.0|       -1.0|           -1.0|         -1.0|        -1.0|           -1.0|       -1.0|        -1.0|        -1.0|        -1.0|        -1.0|       -1.0|\n",
      "|/pdmvserv_task_HI...|   85|   T2_US_Purdue|        85|  Adding last 25 ...|    CMSSWStepFailure|            2|  cmsRun1|     6597.45|       12262.5|     1575.12|1.0002615062761506|381.3951625166715|  6423.0074|   22944.0|                   0.0|3.1037717814653383|       8.42105|          0.0|   129960.0|    34501.3|           -1.0|        -1.0|         -1.0|       -1.0|      0.0162474|         -1.0|     231.735|           -1.0|       -1.0|     890.584|     9604.37|     34498.6|      88.523|       -1.0|\n",
      "|/pdmvserv_task_HI...|   85|   T2_US_Purdue|      8021|An exception of c...|     Fatal Exception|            2|  cmsRun1|     6597.45|       12262.5|     1575.12|1.0002615062761506|381.3951625166715|  6423.0074|   22944.0|                   0.0|3.1037717814653383|       8.42105|          0.0|   129960.0|    34501.3|           -1.0|        -1.0|         -1.0|       -1.0|      0.0162474|         -1.0|     231.735|           -1.0|       -1.0|     890.584|     9604.37|     34498.6|      88.523|       -1.0|\n",
      "+--------------------+-----+---------------+----------+--------------------+--------------------+-------------+---------+------------+--------------+------------+------------------+-----------------+-----------+----------+----------------------+------------------+--------------+-------------+-----------+-----------+---------------+------------+-------------+-----------+---------------+-------------+------------+---------------+-----------+------------+------------+------------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df.join(labeled_failing_tasks, ['task_name', 'error', 'site'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+----------+--------------------+--------------------+-------------+---------+------------+-------+\n",
      "|           task_name|error|        site|exit_codes|           error_msg|          error_type|steps_counter|    names|peakvaluerss|    _c0|\n",
      "+--------------------+-----+------------+----------+--------------------+--------------------+-------------+---------+------------+-------+\n",
      "|/pdmvserv_task_B2...|   92|T2_ES_CIEMAT|     99996|Failed to find a ...|ReportManipulatin...|            0|stageOut1|        -1.0| 136664|\n",
      "|/pdmvserv_task_B2...|   92|T2_ES_CIEMAT|        92|  Adding last 25 ...|    CMSSWStepFailure|            2|  cmsRun1|        -1.0| 136664|\n",
      "|/pdmvserv_task_B2...|   92|T2_ES_CIEMAT|      8028|An exception of c...|     Fatal Exception|            2|  cmsRun1|        -1.0| 136664|\n",
      "|/pdmvserv_task_B2...|   92|T2_ES_CIEMAT|     99999|Adding extra erro...|ErrorLoggingAddition|            2|  cmsRun1|        -1.0| 136664|\n",
      "|/pdmvserv_task_B2...|   92|T2_ES_CIEMAT|        92|<@========== WMEx...|WMAgentStepExecut...|            2|  cmsRun1|        -1.0| 136664|\n",
      "|/pdmvserv_task_HI...|   87|T2_US_Purdue|     99996|Failed to find a ...|ReportManipulatin...|            0|stageOut1|        -1.0|1998147|\n",
      "|/pdmvserv_task_HI...|   87|T2_US_Purdue|        87|  Adding last 25 ...|    CMSSWStepFailure|            2|  cmsRun1|     11172.4|1998147|\n",
      "|/pdmvserv_task_HI...|   87|T2_US_Purdue|      8023|An exception of c...|     Fatal Exception|            2|  cmsRun1|     11172.4|1998147|\n",
      "|/pdmvserv_task_HI...|   87|T2_US_Purdue|     99999|Adding extra erro...|ErrorLoggingAddition|            2|  cmsRun1|     11172.4|1998147|\n",
      "|/pdmvserv_task_HI...|   87|T2_US_Purdue|        87|<@========== WMEx...|WMAgentStepExecut...|            2|  cmsRun1|     11172.4|1998147|\n",
      "|/pdmvserv_task_HI...| 8028|T2_US_Purdue|     99996|Failed to find a ...|ReportManipulatin...|            0|stageOut1|        -1.0|  19483|\n",
      "|/pdmvserv_task_HI...| 8028|T2_US_Purdue|      8028|An exception of c...|     Fatal Exception|            2|  cmsRun1|        -1.0|  19483|\n",
      "|/pdmvserv_task_HI...| 8028|T2_US_Purdue|      8028|An exception of c...|     Fatal Exception|            2|  cmsRun1|        -1.0|  19483|\n",
      "|/pdmvserv_task_HI...| 8028|T2_US_Purdue|      8028|Error in CMSSW: 8...|Error running cms...|            2|  cmsRun1|        -1.0|  19483|\n",
      "|/pdmvserv_task_HI...| 8028|T2_US_Purdue|      8028|<@========== WMEx...|WMAgentStepExecut...|            2|  cmsRun1|        -1.0|  19483|\n",
      "|/pdmvserv_task_HI...|50513|  T2_IT_Pisa|     99996|Failed to find a ...|ReportManipulatin...|            0|stageOut1|        -1.0| 322621|\n",
      "|/pdmvserv_task_HI...|50513|  T2_IT_Pisa|     60307|<@========== WMEx...|   LogArchiveFailure|            1| logArch1|        -1.0| 322621|\n",
      "|/pdmvserv_task_HI...|50513|  T2_IT_Pisa|     50513|SCRAM scripts fai...|  SCRAMScriptFailure|            2|  cmsRun1|        -1.0| 322621|\n",
      "|/pdmvserv_task_HI...|50513|  T2_IT_Pisa|     50513|<@========== WMEx...|WMAgentStepExecut...|            2|  cmsRun1|        -1.0| 322621|\n",
      "|/pdmvserv_task_HI...|   85|   T2_US_MIT|     99996|Failed to find a ...|ReportManipulatin...|            0|stageOut1|        -1.0| 827071|\n",
      "+--------------------+-----+------------+----------+--------------------+--------------------+-------------+---------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.write.format('com.databricks.spark.csv').save('hdfs:///cms/users/llayer/single_writeout_010117_101117.csv',header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/08/04 13:25:49 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -put actionshistory_300719.csv hdfs://analytix/user/llayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SQLContext, StorageLevel\n",
    "sql = SQLContext(sc)\n",
    "labeled_failing_tasks = (sql.read\n",
    "     .format(\"com.databricks.spark.csv\")\n",
    "     .option(\"header\", \"true\")\n",
    "     .load(\"actionshistory_300719.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "labeled_failing_tasks = labeled_failing_tasks.withColumn(\"error\", labeled_failing_tasks[\"error\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+---------------+\n",
      "|_c0|           task_name|error|           site|\n",
      "+---+--------------------+-----+---------------+\n",
      "|  3|/amaltaro_Run2018...|   85|      T1_UK_RAL|\n",
      "|  4|/amaltaro_Run2018...|50664|     T2_DE_RWTH|\n",
      "|  5|/amaltaro_Run2018...|50664|     T2_DE_RWTH|\n",
      "|  8|/amaltaro_Run2018...|99400| NoReportedSite|\n",
      "|  9|/amaltaro_Run2018...|50664|     T2_DE_RWTH|\n",
      "| 11|/amaltaro_Run2018...|   92|      T2_US_MIT|\n",
      "| 15|/amaltaro_Run2018...|   85|   T2_PL_Swierk|\n",
      "| 18|/amaltaro_Run2018...|50664| T2_CH_CERN_HLT|\n",
      "| 22|/amaltaro_Run2018...|   85|      T2_US_MIT|\n",
      "| 24|/amaltaro_Run2018...|   85|T1_US_FNAL_Disk|\n",
      "| 25|/amaltaro_Run2018...|   85|T1_US_FNAL_Disk|\n",
      "| 26|/amaltaro_Run2018...|   85|T1_US_FNAL_Disk|\n",
      "| 27|/amaltaro_Run2018...|   85|T1_US_FNAL_Disk|\n",
      "| 31|/amaltaro_Run2018...|   85|T1_US_FNAL_Disk|\n",
      "| 34|/amaltaro_Run2018...|   85|T1_US_FNAL_Disk|\n",
      "| 35|/amaltaro_task_BT...|50664|     T1_US_FNAL|\n",
      "| 36|/amaltaro_task_BT...|50660|     T1_RU_JINR|\n",
      "| 37|/areinsvo_task_EX...|71104|        Unknown|\n",
      "| 38|/areinsvo_task_HI...|99303|      T1_ES_PIC|\n",
      "| 39|/areinsvo_task_HI...|99303| T2_HU_Budapest|\n",
      "+---+--------------------+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labeled_failing_tasks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_for_problem(row):\n",
    "    #task_name = row[0]\n",
    "    rec = row[0]\n",
    "    task_name = rec[\"task\"]\n",
    "    #task_name = row[0]\n",
    "    #error = row[2]\n",
    "    #test_task = '/pdmvserv_task_HIG-RunIIFall17wmLHEGS-03477__v1_T_190208_210318_4829/HIG-RunIIFall17wmLHEGS-03477_0'\n",
    "    #test_error = 99109\n",
    "    #test_task = '/pdmvserv_task_B2G-RunIISummer15wmLHEGS-01375__v1_T_180703_203928_6625/B2G-RunIISummer15wmLHEGS-01375_0'\n",
    "    #test_task = '/pdmvserv_task_HIG-RunIIFall17wmLHEGS-00630__v1_T_180216_120647_5907/HIG-RunIIFall17wmLHEGS-00630_0/HIG-RunIIFall17DRPremix-00737_0'\n",
    "    #test_task = '/vlimant_ACDC0_task_HIG-RunIIFall17wmLHEGS-01415__v1_T_180706_002124_986/HIG-RunIIFall17DRPremix-02001_1/HIG-RunIIFall17DRPremix-02001_1MergeAODSIMoutput/HIG-RunIIFall17MiniAODv2-01299_0'\n",
    "    #test_error = 85\n",
    "    #test_task = '/pdmvserv_task_HIG-RunIIFall17wmLHEGS-00689__v1_T_180307_201555_2433/HIG-RunIIFall17wmLHEGS-00689_0/HIG-RunIIFall17DRPremix-00886_0'\n",
    "    test_task = '/pdmvserv_task_HIG-RunIIFall17wmLHEGS-02145__v1_T_180705_162228_8813/HIG-RunIIFall17wmLHEGS-02145_0/HIG-RunIIFall17DRPremix-02708_0'\n",
    "    if (task_name == test_task): # and (error == test_error):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures = avro_rdd.filter(lambda x : getFailing(x)).filter(lambda x : filter_for_problem(x))\n",
    "#failures = avro_rdd.filter(lambda x : getFailing(x)).flatMap(lambda x : avro_rdd_KV(x)).filter(lambda x : filter_for_problem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures.saveAsTextFile(\"hdfs:///cms/users/llayer/debug5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = failures.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('test_task.pkl', 'wb') as f:\n",
    "    pickle.dump(examples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'PFNArrayRef', u'task', u'PrepID', u'skippedFiles', u'Campaign', u'wmaid', u'dtype', u'wmats', u'fallbackFiles', u'LFNArray', u'meta_data', u'steps', u'PFNArray', u'LFNArrayRef', u'stype']\n"
     ]
    }
   ],
   "source": [
    "print list(example[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'status', u'errors', u'name', u'stop', u'site', u'start', u'performance', u'output', u'input']\n"
     ]
    }
   ],
   "source": [
    "print list(example[0][0][u'steps'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'type', u'details', u'exitCode']\n"
     ]
    }
   ],
   "source": [
    "print list(example[0][0][u'steps'][2]['errors'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 CMSSWStepFailure\n",
      "8021 Fatal Exception\n",
      "8021 Fatal Exception\n",
      "8021 Fatal Exception\n",
      "8021 Fatal Exception\n",
      "8021 Fatal Exception\n",
      "8021 Fatal Exception\n",
      "99999 ErrorLoggingAddition\n",
      "85 WMAgentStepExecutionError\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(example[0][0][u'steps'][2]['errors'])):\n",
    "    print example[0][0][u'steps'][2]['errors'][i]['exitCode'], example[0][0][u'steps'][2]['errors'][i]['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = failures.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print len(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1_UK_RAL 85\n",
      "T1_UK_RAL 85\n",
      "T1_UK_RAL 85\n",
      "T1_UK_RAL 85\n",
      "T1_UK_RAL 85\n",
      "T1_UK_RAL 85\n",
      "T1_FR_CCIN2P3 85\n",
      "T1_FR_CCIN2P3 85\n",
      "T1_UK_RAL 85\n",
      "T1_UK_RAL 85\n",
      "T1_UK_RAL 85\n",
      "T1_UK_RAL 85\n"
     ]
    }
   ],
   "source": [
    "for prob in probs:\n",
    "    print prob[1], prob[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_key(row):\n",
    "    return (row[0], row[1], row[2]), row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((u'/pdmvserv_task_SMP-RunIISummer16DR80Premix-00011__v1_T_161227_083845_4347/SMP-RunIISummer16DR80Premix-00011_0', u'T2_UK_London_IC', 99999), u'Could not find report file for step stageOut1!')]\n"
     ]
    }
   ],
   "source": [
    "print failing_workflows.map(lambda x : map_to_key(x)).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceToLongest(row):\n",
    "    key = row[0]\n",
    "    message_list = list(row[1])\n",
    "    longest_msg = ''\n",
    "    for msg in message_list:\n",
    "        if len(msg) > len(longest_msg):\n",
    "            longest_msg = msg\n",
    "    return key[0], key[1], key[2], longest_msg\n",
    "\n",
    "failing_workflows_reduce = failing_workflows.map(lambda x : map_to_key(x)).groupByKey().map(lambda x : reduceToLongest(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "failing_workflows_df = failing_workflows_reduce.toDF([\"task_name\", \"site\", \"error\", \"error_msg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-----+--------------------+\n",
      "|           task_name|           site|error|           error_msg|\n",
      "+--------------------+---------------+-----+--------------------+\n",
      "|/pdmvserv_task_BP...|     T2_DE_DESY|   80|  Adding last 25 ...|\n",
      "|/fabozzi_Run2016H...|   T2_US_Purdue|99109|Error in StageOut...|\n",
      "|/pdmvserv_task_B2...|           null|99303|Could not find jo...|\n",
      "|/pdmvserv_task_HI...|T2_FR_GRIF_IRFU|  134|  Adding last 25 ...|\n",
      "|/fabozzi_Run2016B...|     T1_RU_JINR|99999|Adding extra erro...|\n",
      "|/pdmvserv_task_SU...|      T1_UK_RAL|  139|  Adding last 25 ...|\n",
      "|/pdmvserv_task_EX...|T2_US_Wisconsin| 8001|Exit 8001: CMSExe...|\n",
      "|/prebello_Run2016...|   T2_US_Purdue| 8022|An exception of c...|\n",
      "|/prozober_ACDC0_t...|     T2_CH_CERN|99999|Adding extra erro...|\n",
      "|/pdmvserv_task_HI...|     T2_DE_RWTH| 8028|An exception of c...|\n",
      "|/pdmvserv_task_EG...|     T2_US_UCSD|   85|  Adding last 25 ...|\n",
      "|/pdmvserv_task_B2...|      T1_UK_RAL| 8001|Exit 8001: CMSExe...|\n",
      "|/pdmvserv_task_EX...|  T2_US_Florida|99999|Adding extra erro...|\n",
      "|/pdmvserv_task_TS...|   T2_US_Purdue|  139|  Adding last 25 ...|\n",
      "|/pdmvserv_task_EX...| T2_CH_CERN_HLT|50115|Error reading XML...|\n",
      "|/pdmvserv_task_B2...| T2_US_Nebraska|99999|Adding extra erro...|\n",
      "|/pdmvserv_task_HI...|T2_FR_GRIF_IRFU|  139|  Adding last 25 ...|\n",
      "|/pdmvserv_task_TO...|T1_US_FNAL_Disk|  134|  Adding last 25 ...|\n",
      "|/pdmvserv_task_TO...|      T2_US_MIT| 8028|An exception of c...|\n",
      "|/pdmvserv_task_EX...|      T1_ES_PIC|   85|  Adding last 25 ...|\n",
      "+--------------------+---------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "failing_workflows_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4159"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failing_workflows_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "failing_workflows_df_rep = failing_workflows_df.repartition(500)\n",
    "print failing_workflows_df_rep.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load actionhist and convert to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SQLContext, StorageLevel\n",
    "sql = SQLContext(sc)\n",
    "labeled_failing_tasks = (sql.read\n",
    "     .format(\"com.databricks.spark.csv\")\n",
    "     .option(\"header\", \"true\")\n",
    "     .load(\"hdfs:///cms/users/llayer/actionhist.csv\"))\n",
    "\n",
    "#rdd_failing_tasks = rdd_failing_tasks.rdd.map(tuple)\n",
    "#print rdd_failing_tasks.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(task_name=u'/vlimant_ACDC0_task_HIG-RunIIFall17wmLHEGS-01415__v1_T_180706_002124_986/HIG-RunIIFall17DRPremix-02001_1/HIG-RunIIFall17DRPremix-02001_1MergeAODSIMoutput/HIG-RunIIFall17MiniAODv2-01299_0', side_state=u'good_site', error=85, site=u'T1_UK_RAL', action=u'acdc', memory=None)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "labeled_failing_tasks = labeled_failing_tasks.withColumn(\"error\", labeled_failing_tasks[\"error\"].cast(IntegerType()))\n",
    "print labeled_failing_tasks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Join both frames and save to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = failing_workflows_df.join(labeled_failing_tasks, ['task_name','site', 'error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format('com.databricks.spark.csv').save('hdfs:///cms/users/llayer/df_reduced_codes2.csv',header = 'true')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "sparkconnect": {
   "bundled_options": [
    "CMSSpark"
   ],
   "list_of_options": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
