{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronize and compare the wmarchive to the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load failing workflow from wmarchive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filter_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_task = '/pdmvserv_task_HIG-RunIIFall17wmLHEGS-02145__v1_T_180705_162228_8813/HIG-RunIIFall17wmLHEGS-02145_0/HIG-RunIIFall17DRPremix-02708_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time range has to include the desired workflow \n",
    "timerange = [20180704, 20181004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20180704, 20181004]\n",
      "['hdfs:///cms/wmarchive/avro/fwjr/2018/07/04', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/05', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/06', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/07', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/08', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/09', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/10', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/11', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/12', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/13', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/14', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/15', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/16', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/17', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/18', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/19', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/20', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/21', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/22', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/23', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/24', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/25', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/26', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/27', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/28', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/29', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/30', 'hdfs:///cms/wmarchive/avro/fwjr/2018/07/31', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/01', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/02', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/03', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/06', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/07', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/08', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/09', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/10', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/11', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/12', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/13', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/14', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/15', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/16', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/20', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/22', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/23', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/24', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/25', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/26', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/27', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/28', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/29', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/30', 'hdfs:///cms/wmarchive/avro/fwjr/2018/08/31', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/01', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/02', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/03', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/04', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/05', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/06', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/07', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/08', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/09', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/10', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/11', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/12', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/13', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/14', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/15', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/16', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/17', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/18', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/19', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/20', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/21', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/22', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/23', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/24', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/25', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/26', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/27', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/28', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/29', 'hdfs:///cms/wmarchive/avro/fwjr/2018/09/30', 'hdfs:///cms/wmarchive/avro/fwjr/2018/10/01', 'hdfs:///cms/wmarchive/avro/fwjr/2018/10/02', 'hdfs:///cms/wmarchive/avro/fwjr/2018/10/03', 'hdfs:///cms/wmarchive/avro/fwjr/2018/10/04']\n"
     ]
    }
   ],
   "source": [
    "# Load the data in the timerange\n",
    "avro_rdd = filter_messages.load_data(sc, timerange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the tasks - keep only failing \n",
    "def getFailing(row):\n",
    "    rec = row[0]\n",
    "    task_name = rec[\"task\"]\n",
    "    meta = rec.get('meta_data', {})\n",
    "    if task_name != test_task: \n",
    "        return False\n",
    "    if meta.get('jobstate', '') != 'jobfailed':\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures = avro_rdd.filter(lambda x : getFailing(x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print len(failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to disk\n",
    "import pickle\n",
    "path = 'data/test_task.pkl'\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(failures, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the console workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the actionshistory\n",
    "data = pd.read_json('/eos/user/l/llayer/AIErrorLogAnalysis/spark/data/actionshistory_300719.json', orient='index')\n",
    "# Reset index\n",
    "data_index_reset = data.reset_index()\n",
    "data_index_reset = data_index_reset.rename(columns={'index': 'task_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "console_wf = data_index_reset[data_index_reset['task_name'] == test_task].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()   # start with x's keys and values\n",
    "    z.update(y)    # modifies z with y's keys and values & returns None\n",
    "    return z\n",
    "\n",
    "console_wf_site_dict = merge_two_dicts(console_wf['errors']['good_sites'], console_wf['errors']['bad_sites'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'11003': {u'T1_FR_CCIN2P3': 1, u'T1_UK_RAL': 1, u'T2_US_Florida': 1, u'T1_RU_JINR': 2}, u'71305': {u'T2_CH_CERN_HLT': 7}, u'99303': {u'T2_IT_Rome': 2}, u'-1': {u'T1_ES_PIC_Disk': 1, u'T2_IT_Rome': 1, u'T1_FR_CCIN2P3_Disk': 1, u'T1_DE_KIT_Disk': 1, u'T1_IT_CNAF_Disk': 1, u'T1_RU_JINR_Disk': 1, u'T1_UK_RAL_Disk': 1}, u'99400': {u'NoReportedSite': 1}, u'71104': {u'Unknown': 1}, u'92': {u'T2_DE_RWTH': 1, u'T1_ES_PIC': 1, u'T2_UK_London_IC': 2, u'T2_UK_London_Brunel': 2, u'T2_US_Purdue': 1}, u'85': {u'T2_BE_IIHE': 1, u'T2_US_Purdue': 1, u'T2_FR_IPHC': 2}, u'50115': {u'T2_US_UCSD': 1}}\n"
     ]
    }
   ],
   "source": [
    "print console_wf_site_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare the entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with sites and error codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_code = '85'\n",
    "test_site = 'T2_US_Purdue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_console_entries(sites, test_code = None, test_site = None):\n",
    "    counter = 0\n",
    "    for error, site_dict in sites.iteritems():\n",
    "        \n",
    "        if test_code is not None:\n",
    "            if error != test_code:\n",
    "                continue        \n",
    "        \n",
    "        for site, count in site_dict.iteritems():\n",
    "            \n",
    "            if test_site is not None:\n",
    "                if site != test_site:\n",
    "                    continue\n",
    "\n",
    "            counter += count\n",
    "            print error, site, count\n",
    "            \n",
    "    print 'Total counts console', counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_wmarchive_entries(entry, test_code = None, test_site = None):\n",
    "\n",
    "    steps = entry[0][u'steps']\n",
    "    found_entry = False\n",
    "    for n in range(len(steps)):\n",
    "        \n",
    "        errors = steps[n]['errors']\n",
    "        site = steps[n]['site']\n",
    "        if test_site is not None:\n",
    "            if site != test_site:\n",
    "                continue\n",
    "            \n",
    "        for i in range(len(errors)):\n",
    "   \n",
    "            error = errors[i]['exitCode']\n",
    "            \n",
    "            if test_code is not None:\n",
    "                if error != int(test_code):\n",
    "                    continue   \n",
    "                    \n",
    "            error_type = errors[i]['type']\n",
    "            print 'Step', n\n",
    "            print error, error_type, site\n",
    "            \n",
    "            found_entry = True\n",
    "            \n",
    "    return found_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 T2_US_Purdue 1\n",
      "Total counts console 1\n"
     ]
    }
   ],
   "source": [
    "print_console_entries(console_wf_site_dict, test_code, test_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2\n",
      "85 CMSSWStepFailure T2_US_Purdue\n",
      "Step 2\n",
      "85 WMAgentStepExecutionError T2_US_Purdue\n",
      "\n",
      "Total wmarchive entries: 1\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i, entry in enumerate(failures):\n",
    "    \n",
    "    found = print_wmarchive_entries(entry, test_code, test_site)\n",
    "    if found == True:\n",
    "        print\n",
    "    counter += found\n",
    "    \n",
    "print 'Total wmarchive entries:', counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the wmarchive entries missing in actionshistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wmarchive_entries(entries, test_code, test_site):\n",
    "    \n",
    "    for entry in entries:\n",
    "        \n",
    "        steps = entry[0][u'steps']\n",
    "        found_entry = False\n",
    "        \n",
    "        for n in range(len(steps)):   \n",
    "            errors = steps[n]['errors']\n",
    "            site = steps[n]['site']  \n",
    "            if site != test_site:\n",
    "                continue\n",
    "            \n",
    "            for i in range(len(errors)):\n",
    "                error = errors[i]['exitCode']\n",
    "                if error != int(test_code):\n",
    "                    continue\n",
    "                else:\n",
    "                    return True\n",
    "        \n",
    "    \n",
    "\n",
    "def print_missing_wmarchive(sites):\n",
    "    \n",
    "    for error, site_dict in sites.iteritems():\n",
    "        for site, count in site_dict.iteritems():\n",
    "            if search_wmarchive_entries(failures, error, site) == True:\n",
    "                continue\n",
    "            else:\n",
    "                print error, site, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71305 T2_CH_CERN_HLT 7\n",
      "-1 T1_ES_PIC_Disk 1\n",
      "-1 T2_IT_Rome 1\n",
      "-1 T1_FR_CCIN2P3_Disk 1\n",
      "-1 T1_DE_KIT_Disk 1\n",
      "-1 T1_IT_CNAF_Disk 1\n",
      "-1 T1_RU_JINR_Disk 1\n",
      "-1 T1_UK_RAL_Disk 1\n",
      "71104 Unknown 1\n"
     ]
    }
   ],
   "source": [
    "print_missing_wmarchive(console_wf_site_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "sparkconnect": {
   "bundled_options": [
    "CMSSpark"
   ],
   "list_of_options": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
