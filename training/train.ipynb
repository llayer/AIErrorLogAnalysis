{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the operator action prediction model with w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the dataloaders for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clas to load the data\n",
    "class LogData(data.Data):\n",
    "    \n",
    "    def load_data(self, in_file):\n",
    "\n",
    "        \"\"\"Loads numpy arrays from H5 pandas file \n",
    "            TODO: check preloading\"\"\"\n",
    "        \n",
    "        h5_file = pd.read_hdf( in_file )\n",
    "        X1 = h5_file['table_flattened'].values\n",
    "        X1 = np.array(list(X1))\n",
    "        Y = h5_file['action_binary_encoded'].values\n",
    "        print len(X1)\n",
    "        return X1,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 2, 6, 18, 13, 21, 16, 8, 20, 9, 1, 23, 3, 25, 22, 19, 17, 12, 24, 5, 4, 15, 0, 7, 14]\n",
      "[10, 11, 2, 6, 18, 13, 21, 16, 8, 20, 9, 1, 23, 3]\n",
      "[25, 22, 19, 17]\n"
     ]
    }
   ],
   "source": [
    "# Randomly shuffle the input files for the training and testing\n",
    "\n",
    "file_ids = range(0, 26)\n",
    "\n",
    "import random\n",
    "SEED = 30\n",
    "\n",
    "random.seed(SEED)\n",
    "random.shuffle(file_ids)\n",
    "\n",
    "print file_ids\n",
    "train_ids = file_ids[0:14]\n",
    "test_ids = file_ids[14:18]\n",
    "print train_ids\n",
    "print test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names for the training and test\n",
    "inFiles_train = []\n",
    "inFiles = []\n",
    "path = '/bigdata/shared/AIErrorHandling/'\n",
    "for i in train_ids:\n",
    "    inFiles_train.append(path + 'w2v_matrix' + str(i) + '.h5')\n",
    "inFiles_test = []\n",
    "for i in test_ids:\n",
    "    inFiles_test.append(path + 'w2v_matrix' + str(i) + '.h5')\n",
    "for i in file_ids:\n",
    "    inFiles.append(path + 'w2v_matrix' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "loader_train = LogData(batch_size=batch_size)\n",
    "loader_test = LogData(batch_size=batch_size)\n",
    "loader_train.set_file_names(inFiles_train)\n",
    "loader_test.set_file_names(inFiles_test)\n",
    "loader = LogData(batch_size=batch_size)\n",
    "loader.set_file_names(inFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/bigdata/shared/AIErrorHandling/w2v_matrix10.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix11.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix2.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix6.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix18.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix13.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix21.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix16.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix8.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix20.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix9.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix1.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix23.h5', '/bigdata/shared/AIErrorHandling/w2v_matrix3.h5']\n"
     ]
    }
   ],
   "source": [
    "print loader_train.file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "90\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for x,y in loader.generate_data():\n",
    "    \n",
    "    X.append(x)\n",
    "    Y.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.concatenate(Y)\n",
    "X = np.concatenate(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25090, 64, 1661)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple fully connected dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "#def auroc(y_true, y_pred):\n",
    "#    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(151, 704)))\n",
    "model.add(Dense(100,    activation='relu' ) )\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100,    activation='relu' ) )\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100,    activation='relu' ) )\n",
    "model.add(Dropout(0.5))\n",
    "model.add( Dense( 1 , activation='sigmoid' ) )\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.0), \n",
    "              metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "flatten_1 (Flatten)              (None, 106304)        0           flatten_input_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           10630500    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           10100       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 100)           10100       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 100)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             101         dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 10,650,801\n",
      "Trainable params: 10,650,801\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Sequential.fit_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print len(loader_train.file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-69e85ecd15ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator(loader_train.generate_data(), samples_per_epoch=13000, nb_epoch=1,\n\u001b[0;32m----> 2\u001b[0;31m                     alidation_data=(test_X, test_y), callbacks=[metrics] )\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_X' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit_generator(loader_train.generate_data(), samples_per_epoch=13000, nb_epoch=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12985/12985 [==============================] - 16s - loss: 0.3251 - acc: 0.9344 - auc: 0.5021    \n",
      "Epoch 2/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2561 - acc: 0.9386 - auc: 0.5533    \n",
      "Epoch 3/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2449 - acc: 0.9386 - auc: 0.5853    \n",
      "Epoch 4/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2377 - acc: 0.9386 - auc: 0.6039    \n",
      "Epoch 5/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2344 - acc: 0.9386 - auc: 0.6184    \n",
      "Epoch 6/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2305 - acc: 0.9385 - auc: 0.6306    \n",
      "Epoch 7/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2284 - acc: 0.9387 - auc: 0.6399    \n",
      "Epoch 8/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2232 - acc: 0.9385 - auc: 0.6487    \n",
      "Epoch 9/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2232 - acc: 0.9385 - auc: 0.6567    \n",
      "Epoch 10/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2188 - acc: 0.9386 - auc: 0.6647    \n",
      "Epoch 11/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2153 - acc: 0.9382 - auc: 0.6723    \n",
      "Epoch 12/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2155 - acc: 0.9387 - auc: 0.6785    \n",
      "Epoch 13/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2091 - acc: 0.9385 - auc: 0.6843    \n",
      "Epoch 14/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2131 - acc: 0.9385 - auc: 0.6898    \n",
      "Epoch 15/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2086 - acc: 0.9386 - auc: 0.6948    \n",
      "Epoch 16/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2076 - acc: 0.9382 - auc: 0.7002    \n",
      "Epoch 17/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2067 - acc: 0.9386 - auc: 0.7049    \n",
      "Epoch 18/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2041 - acc: 0.9383 - auc: 0.7087    \n",
      "Epoch 19/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2049 - acc: 0.9385 - auc: 0.7124    \n",
      "Epoch 20/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2003 - acc: 0.9389 - auc: 0.7162    \n",
      "Epoch 21/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2033 - acc: 0.9390 - auc: 0.7200    \n",
      "Epoch 22/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.2005 - acc: 0.9390 - auc: 0.7235    \n",
      "Epoch 23/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1985 - acc: 0.9397 - auc: 0.7267    \n",
      "Epoch 24/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1967 - acc: 0.9394 - auc: 0.7299    \n",
      "Epoch 25/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1943 - acc: 0.9394 - auc: 0.7330    \n",
      "Epoch 26/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1944 - acc: 0.9402 - auc: 0.7359    \n",
      "Epoch 27/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1918 - acc: 0.9412 - auc: 0.7388    \n",
      "Epoch 28/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1934 - acc: 0.9416 - auc: 0.7413    \n",
      "Epoch 29/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1945 - acc: 0.9405 - auc: 0.7441    \n",
      "Epoch 30/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1921 - acc: 0.9412 - auc: 0.7461    \n",
      "Epoch 31/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1906 - acc: 0.9429 - auc: 0.7488    \n",
      "Epoch 32/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1882 - acc: 0.9420 - auc: 0.7509    \n",
      "Epoch 33/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1887 - acc: 0.9446 - auc: 0.7530    \n",
      "Epoch 34/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1846 - acc: 0.9454 - auc: 0.7552    \n",
      "Epoch 35/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1863 - acc: 0.9433 - auc: 0.7575    \n",
      "Epoch 36/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1851 - acc: 0.9440 - auc: 0.7594    \n",
      "Epoch 37/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1856 - acc: 0.9446 - auc: 0.7613    \n",
      "Epoch 38/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1776 - acc: 0.9459 - auc: 0.7633    \n",
      "Epoch 39/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1815 - acc: 0.9442 - auc: 0.7654    \n",
      "Epoch 40/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1791 - acc: 0.9457 - auc: 0.7674    \n",
      "Epoch 41/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1789 - acc: 0.9459 - auc: 0.7692    \n",
      "Epoch 42/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1779 - acc: 0.9465 - auc: 0.7710    \n",
      "Epoch 43/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1789 - acc: 0.9474 - auc: 0.7726    \n",
      "Epoch 44/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1799 - acc: 0.9470 - auc: 0.7743    \n",
      "Epoch 45/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1778 - acc: 0.9472 - auc: 0.7759    \n",
      "Epoch 46/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1788 - acc: 0.9476 - auc: 0.7773    \n",
      "Epoch 47/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1775 - acc: 0.9478 - auc: 0.7789    \n",
      "Epoch 48/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1739 - acc: 0.9481 - auc: 0.7802    \n",
      "Epoch 49/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1737 - acc: 0.9484 - auc: 0.7818    \n",
      "Epoch 50/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1774 - acc: 0.9474 - auc: 0.7831    \n",
      "Epoch 51/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1741 - acc: 0.9489 - auc: 0.7845    \n",
      "Epoch 52/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1740 - acc: 0.9482 - auc: 0.7857    \n",
      "Epoch 53/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1687 - acc: 0.9496 - auc: 0.7871    \n",
      "Epoch 54/200\n",
      "12985/12985 [==============================] - 16s - loss: 0.1701 - acc: 0.9506 - auc: 0.7886    \n",
      "Epoch 55/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1707 - acc: 0.9488 - auc: 0.7899    \n",
      "Epoch 56/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1674 - acc: 0.9492 - auc: 0.7911    \n",
      "Epoch 57/200\n",
      "12985/12985 [==============================] - 16s - loss: 0.1701 - acc: 0.9481 - auc: 0.7924    \n",
      "Epoch 58/200\n",
      "12985/12985 [==============================] - 16s - loss: 0.1701 - acc: 0.9503 - auc: 0.7936    \n",
      "Epoch 59/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1708 - acc: 0.9503 - auc: 0.7947    \n",
      "Epoch 60/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1685 - acc: 0.9506 - auc: 0.7957    \n",
      "Epoch 61/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1680 - acc: 0.9489 - auc: 0.7968    \n",
      "Epoch 62/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1688 - acc: 0.9487 - auc: 0.7979    \n",
      "Epoch 63/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1678 - acc: 0.9511 - auc: 0.7991    \n",
      "Epoch 64/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1692 - acc: 0.9508 - auc: 0.8000    \n",
      "Epoch 65/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1665 - acc: 0.9512 - auc: 0.8010    \n",
      "Epoch 66/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1675 - acc: 0.9512 - auc: 0.8019    \n",
      "Epoch 67/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1629 - acc: 0.9521 - auc: 0.8028    \n",
      "Epoch 68/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1632 - acc: 0.9519 - auc: 0.8039    \n",
      "Epoch 69/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1609 - acc: 0.9514 - auc: 0.8049    \n",
      "Epoch 70/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1634 - acc: 0.9515 - auc: 0.8059    \n",
      "Epoch 71/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1678 - acc: 0.9521 - auc: 0.8068    \n",
      "Epoch 72/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1634 - acc: 0.9520 - auc: 0.8076    \n",
      "Epoch 73/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1633 - acc: 0.9517 - auc: 0.8085    \n",
      "Epoch 74/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1660 - acc: 0.9527 - auc: 0.8092    \n",
      "Epoch 75/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1627 - acc: 0.9520 - auc: 0.8100    \n",
      "Epoch 76/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1628 - acc: 0.9525 - auc: 0.8108    \n",
      "Epoch 77/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1617 - acc: 0.9525 - auc: 0.8116    \n",
      "Epoch 78/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1646 - acc: 0.9522 - auc: 0.8122    \n",
      "Epoch 79/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1631 - acc: 0.9524 - auc: 0.8129    \n",
      "Epoch 80/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1653 - acc: 0.9524 - auc: 0.8137    \n",
      "Epoch 81/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1601 - acc: 0.9533 - auc: 0.8144    \n",
      "Epoch 82/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1609 - acc: 0.9521 - auc: 0.8150    \n",
      "Epoch 83/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1613 - acc: 0.9526 - auc: 0.8158    \n",
      "Epoch 84/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1614 - acc: 0.9528 - auc: 0.8165    \n",
      "Epoch 85/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1626 - acc: 0.9529 - auc: 0.8171    \n",
      "Epoch 86/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1577 - acc: 0.9543 - auc: 0.8177    \n",
      "Epoch 87/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1584 - acc: 0.9527 - auc: 0.8185    \n",
      "Epoch 88/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1580 - acc: 0.9543 - auc: 0.8192    \n",
      "Epoch 89/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1606 - acc: 0.9517 - auc: 0.8198    \n",
      "Epoch 90/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1605 - acc: 0.9525 - auc: 0.8205    \n",
      "Epoch 91/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1584 - acc: 0.9533 - auc: 0.8212    \n",
      "Epoch 92/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1576 - acc: 0.9542 - auc: 0.8218    \n",
      "Epoch 93/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1612 - acc: 0.9526 - auc: 0.8223    \n",
      "Epoch 94/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1587 - acc: 0.9543 - auc: 0.8229    \n",
      "Epoch 95/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1634 - acc: 0.9525 - auc: 0.8234    \n",
      "Epoch 96/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1639 - acc: 0.9538 - auc: 0.8239    \n",
      "Epoch 97/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1573 - acc: 0.9554 - auc: 0.8244    \n",
      "Epoch 98/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1580 - acc: 0.9533 - auc: 0.8250    \n",
      "Epoch 99/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1559 - acc: 0.9543 - auc: 0.8255    \n",
      "Epoch 100/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1579 - acc: 0.9541 - auc: 0.8261    \n",
      "Epoch 101/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1564 - acc: 0.9548 - auc: 0.8265    \n",
      "Epoch 102/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1559 - acc: 0.9531 - auc: 0.8271    \n",
      "Epoch 103/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1541 - acc: 0.9544 - auc: 0.8276    \n",
      "Epoch 104/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1561 - acc: 0.9536 - auc: 0.8283    \n",
      "Epoch 105/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1600 - acc: 0.9537 - auc: 0.8287    \n",
      "Epoch 106/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1589 - acc: 0.9541 - auc: 0.8292    \n",
      "Epoch 107/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1568 - acc: 0.9554 - auc: 0.8298    \n",
      "Epoch 108/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1568 - acc: 0.9547 - auc: 0.8302    \n",
      "Epoch 109/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1594 - acc: 0.9548 - auc: 0.8306    \n",
      "Epoch 110/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1534 - acc: 0.9545 - auc: 0.8311    \n",
      "Epoch 111/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1547 - acc: 0.9538 - auc: 0.8317    \n",
      "Epoch 112/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1570 - acc: 0.9543 - auc: 0.8321    \n",
      "Epoch 113/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1551 - acc: 0.9551 - auc: 0.8325    \n",
      "Epoch 114/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1507 - acc: 0.9563 - auc: 0.8329    \n",
      "Epoch 115/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1540 - acc: 0.9546 - auc: 0.8334    \n",
      "Epoch 116/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1516 - acc: 0.9566 - auc: 0.8339    \n",
      "Epoch 117/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1532 - acc: 0.9542 - auc: 0.8343    \n",
      "Epoch 118/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1546 - acc: 0.9558 - auc: 0.8347    \n",
      "Epoch 119/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1493 - acc: 0.9556 - auc: 0.8352    \n",
      "Epoch 120/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1544 - acc: 0.9551 - auc: 0.8357    \n",
      "Epoch 121/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1548 - acc: 0.9551 - auc: 0.8360    \n",
      "Epoch 122/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1508 - acc: 0.9553 - auc: 0.8365    \n",
      "Epoch 123/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1512 - acc: 0.9556 - auc: 0.8369    \n",
      "Epoch 124/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1504 - acc: 0.9559 - auc: 0.8373    \n",
      "Epoch 125/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1489 - acc: 0.9565 - auc: 0.8378    \n",
      "Epoch 126/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1541 - acc: 0.9538 - auc: 0.8382    \n",
      "Epoch 127/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1542 - acc: 0.9551 - auc: 0.8386    \n",
      "Epoch 128/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1549 - acc: 0.9549 - auc: 0.8390    \n",
      "Epoch 129/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1559 - acc: 0.9536 - auc: 0.8393    \n",
      "Epoch 130/200\n",
      "12985/12985 [==============================] - 16s - loss: 0.1519 - acc: 0.9550 - auc: 0.8397    \n",
      "Epoch 131/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1512 - acc: 0.9564 - auc: 0.8400    \n",
      "Epoch 132/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1533 - acc: 0.9550 - auc: 0.8404    \n",
      "Epoch 133/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1516 - acc: 0.9561 - auc: 0.8408    \n",
      "Epoch 134/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1513 - acc: 0.9566 - auc: 0.8411    \n",
      "Epoch 135/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1499 - acc: 0.9561 - auc: 0.8415    \n",
      "Epoch 136/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1531 - acc: 0.9546 - auc: 0.8418    \n",
      "Epoch 137/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1533 - acc: 0.9559 - auc: 0.8421    \n",
      "Epoch 138/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1517 - acc: 0.9556 - auc: 0.8425    \n",
      "Epoch 139/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1515 - acc: 0.9545 - auc: 0.8428    \n",
      "Epoch 140/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1495 - acc: 0.9562 - auc: 0.8431    \n",
      "Epoch 141/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1514 - acc: 0.9529 - auc: 0.8435    \n",
      "Epoch 142/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1485 - acc: 0.9563 - auc: 0.8439    \n",
      "Epoch 143/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1499 - acc: 0.9559 - auc: 0.8443    \n",
      "Epoch 144/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1509 - acc: 0.9543 - auc: 0.8446    \n",
      "Epoch 145/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1475 - acc: 0.9570 - auc: 0.8450    \n",
      "Epoch 146/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1489 - acc: 0.9564 - auc: 0.8454    \n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12985/12985 [==============================] - 15s - loss: 0.1500 - acc: 0.9565 - auc: 0.8457    \n",
      "Epoch 148/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1475 - acc: 0.9566 - auc: 0.8460    \n",
      "Epoch 149/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1528 - acc: 0.9563 - auc: 0.8463    \n",
      "Epoch 150/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1508 - acc: 0.9556 - auc: 0.8467    \n",
      "Epoch 151/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1461 - acc: 0.9558 - auc: 0.8470    \n",
      "Epoch 152/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1463 - acc: 0.9571 - auc: 0.8473    \n",
      "Epoch 153/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1511 - acc: 0.9550 - auc: 0.8476    \n",
      "Epoch 154/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1493 - acc: 0.9568 - auc: 0.8479    \n",
      "Epoch 155/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1510 - acc: 0.9553 - auc: 0.8482    \n",
      "Epoch 156/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1423 - acc: 0.9573 - auc: 0.8485    \n",
      "Epoch 157/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1491 - acc: 0.9558 - auc: 0.8489    \n",
      "Epoch 158/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1486 - acc: 0.9564 - auc: 0.8492    \n",
      "Epoch 159/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1446 - acc: 0.9579 - auc: 0.8495    \n",
      "Epoch 160/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1509 - acc: 0.9554 - auc: 0.8497    \n",
      "Epoch 161/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1525 - acc: 0.9548 - auc: 0.8500    \n",
      "Epoch 162/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1463 - acc: 0.9569 - auc: 0.8503    \n",
      "Epoch 163/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1464 - acc: 0.9565 - auc: 0.8506    \n",
      "Epoch 164/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1486 - acc: 0.9566 - auc: 0.8508    \n",
      "Epoch 165/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1498 - acc: 0.9559 - auc: 0.8511    \n",
      "Epoch 166/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1471 - acc: 0.9569 - auc: 0.8514    \n",
      "Epoch 167/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1435 - acc: 0.9573 - auc: 0.8517    \n",
      "Epoch 168/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1517 - acc: 0.9534 - auc: 0.8519    \n",
      "Epoch 169/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1432 - acc: 0.9577 - auc: 0.8522    \n",
      "Epoch 170/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1445 - acc: 0.9577 - auc: 0.8525    \n",
      "Epoch 171/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1490 - acc: 0.9559 - auc: 0.8527    \n",
      "Epoch 172/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1472 - acc: 0.9568 - auc: 0.8530    \n",
      "Epoch 173/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1489 - acc: 0.9559 - auc: 0.8533    \n",
      "Epoch 174/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1463 - acc: 0.9568 - auc: 0.8535    \n",
      "Epoch 175/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1497 - acc: 0.9565 - auc: 0.8537    \n",
      "Epoch 176/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1455 - acc: 0.9568 - auc: 0.8540    \n",
      "Epoch 177/200\n",
      "12985/12985 [==============================] - 16s - loss: 0.1447 - acc: 0.9573 - auc: 0.8542    \n",
      "Epoch 178/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1462 - acc: 0.9569 - auc: 0.8545    \n",
      "Epoch 179/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1479 - acc: 0.9566 - auc: 0.8547    \n",
      "Epoch 180/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1519 - acc: 0.9543 - auc: 0.8549    \n",
      "Epoch 181/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1478 - acc: 0.9553 - auc: 0.8551    \n",
      "Epoch 182/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1428 - acc: 0.9578 - auc: 0.8554    \n",
      "Epoch 183/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1434 - acc: 0.9571 - auc: 0.8556    \n",
      "Epoch 184/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1513 - acc: 0.9562 - auc: 0.8559    \n",
      "Epoch 185/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1471 - acc: 0.9564 - auc: 0.8561    \n",
      "Epoch 186/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1427 - acc: 0.9573 - auc: 0.8564    \n",
      "Epoch 187/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1470 - acc: 0.9573 - auc: 0.8566    \n",
      "Epoch 188/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1437 - acc: 0.9573 - auc: 0.8568    \n",
      "Epoch 189/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1435 - acc: 0.9566 - auc: 0.8571    \n",
      "Epoch 190/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1459 - acc: 0.9576 - auc: 0.8573    \n",
      "Epoch 191/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1449 - acc: 0.9570 - auc: 0.8576    \n",
      "Epoch 192/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1435 - acc: 0.9573 - auc: 0.8578    \n",
      "Epoch 193/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1446 - acc: 0.9559 - auc: 0.8580    \n",
      "Epoch 194/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1450 - acc: 0.9564 - auc: 0.8583    \n",
      "Epoch 195/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1494 - acc: 0.9564 - auc: 0.8585    \n",
      "Epoch 196/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1447 - acc: 0.9573 - auc: 0.8587    \n",
      "Epoch 197/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1462 - acc: 0.9560 - auc: 0.8589    \n",
      "Epoch 198/200\n",
      "12985/12985 [==============================] - 16s - loss: 0.1427 - acc: 0.9570 - auc: 0.8591    \n",
      "Epoch 199/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1482 - acc: 0.9561 - auc: 0.8593    \n",
      "Epoch 200/200\n",
      "12985/12985 [==============================] - 15s - loss: 0.1477 - acc: 0.9559 - auc: 0.8595    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd44a7bbbd0>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=100\n",
    "epochs=200\n",
    "validation_split=0.0\n",
    "verbose=1\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=epochs, validation_split=validation_split )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.667391830991\n",
      "0.926968655843\n"
     ]
    }
   ],
   "source": [
    "print roc_auc_score(y_test, y_pred)\n",
    "print roc_auc_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "554\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for X,Y in loader_test.generate_data():\n",
    "    \n",
    "    pred = model.predict(X)\n",
    "    y_pred.append(pred)\n",
    "    y_true.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate(y_pred)\n",
    "y_true = np.concatenate(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3550\n"
     ]
    }
   ],
   "source": [
    "print len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "def ROC(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    plot ROC curve for test dataset\n",
    "    \"\"\"\n",
    "    roc_fpr, roc_tpr, roc_thresholds = roc_curve(y_test, y_pred.ravel() )\n",
    "    roc_auc = auc(roc_fpr , roc_tpr)\n",
    "\n",
    "    roc_plot = plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(roc_fpr, roc_tpr, label='Keras (area = {:.3f})'.format(roc_auc))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROC(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROC(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_generator(loader.generate_data(), val_samples = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.80308864e-02]\n",
      " [  5.93945794e-02]\n",
      " [  5.93945794e-02]\n",
      " [  5.70535362e-02]\n",
      " [  5.93945794e-02]\n",
      " [  1.69053573e-11]\n",
      " [  5.52369654e-02]\n",
      " [  6.26947135e-02]\n",
      " [  5.47897518e-02]\n",
      " [  5.96414208e-02]\n",
      " [  5.96414208e-02]\n",
      " [  5.96414208e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.33787662e-02]\n",
      " [  5.96414208e-02]\n",
      " [  6.98937923e-02]\n",
      " [  4.41190079e-02]\n",
      " [  3.71050090e-02]\n",
      " [  6.26947135e-02]\n",
      " [  5.49029410e-02]\n",
      " [  6.79483637e-02]\n",
      " [  6.52811527e-02]\n",
      " [  6.51219934e-02]\n",
      " [  6.45904243e-02]\n",
      " [  6.21460564e-02]\n",
      " [  6.64102063e-02]\n",
      " [  5.97147234e-02]\n",
      " [  6.58985972e-02]\n",
      " [  6.29624352e-02]\n",
      " [  6.43922538e-02]\n",
      " [  6.52675927e-02]\n",
      " [  6.45904243e-02]\n",
      " [  6.58985972e-02]\n",
      " [  7.08941116e-06]\n",
      " [  6.96100891e-02]\n",
      " [  6.70144111e-02]\n",
      " [  6.52664080e-02]\n",
      " [  6.52664080e-02]\n",
      " [  6.28675967e-02]\n",
      " [  7.17234686e-02]\n",
      " [  9.32889432e-02]\n",
      " [  5.84310293e-02]\n",
      " [  6.67389706e-02]\n",
      " [  6.40776902e-02]\n",
      " [  6.67389706e-02]\n",
      " [  6.67389706e-02]\n",
      " [  5.87887019e-02]\n",
      " [  6.62752837e-02]\n",
      " [  6.88263178e-02]\n",
      " [  6.28458261e-02]\n",
      " [  6.23005889e-02]\n",
      " [  6.20510727e-02]\n",
      " [  6.12548254e-02]\n",
      " [  6.69748038e-02]\n",
      " [  4.74102655e-03]\n",
      " [  5.94537333e-02]\n",
      " [  6.32227734e-02]\n",
      " [  5.44122197e-02]\n",
      " [  6.61006272e-02]\n",
      " [  6.28458261e-02]\n",
      " [  4.38393155e-10]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.67715876e-02]\n",
      " [  4.41035554e-02]\n",
      " [  6.60743192e-02]\n",
      " [  6.28458261e-02]\n",
      " [  6.16642982e-02]\n",
      " [  6.17361777e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.45904243e-02]\n",
      " [  6.84322566e-02]\n",
      " [  5.95708974e-02]\n",
      " [  6.53136298e-02]\n",
      " [  6.45904243e-02]\n",
      " [  6.83909878e-02]\n",
      " [  6.17361777e-02]\n",
      " [  5.85654899e-02]\n",
      " [  6.38242587e-02]\n",
      " [  6.28458261e-02]\n",
      " [  5.01783974e-02]\n",
      " [  6.71529323e-02]\n",
      " [  7.38455877e-02]\n",
      " [  6.91635609e-02]\n",
      " [  6.22152761e-02]\n",
      " [  6.93468824e-02]\n",
      " [  6.60743192e-02]\n",
      " [  7.84344673e-02]\n",
      " [  8.05143490e-02]\n",
      " [  7.68266022e-02]\n",
      " [  6.06031194e-02]\n",
      " [  5.62297516e-02]\n",
      " [  6.92502931e-02]\n",
      " [  5.76643869e-02]\n",
      " [  6.34848326e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.56018837e-02]\n",
      " [  6.61006272e-02]\n",
      " [  7.05792978e-02]\n",
      " [  7.00734258e-02]\n",
      " [  6.43899143e-02]\n",
      " [  6.61774054e-02]\n",
      " [  6.69047832e-02]\n",
      " [  6.60453662e-02]\n",
      " [  6.75370917e-02]\n",
      " [  6.95231929e-02]\n",
      " [  6.99743554e-02]\n",
      " [  6.45904243e-02]\n",
      " [  3.16924043e-02]\n",
      " [  6.69748038e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.28458261e-02]\n",
      " [  6.63170666e-02]\n",
      " [  6.50409386e-02]\n",
      " [  6.83325604e-02]\n",
      " [  6.28458261e-02]\n",
      " [  6.13089204e-02]\n",
      " [  5.85426874e-02]\n",
      " [  7.89361969e-02]\n",
      " [  7.11111873e-02]\n",
      " [  7.55404308e-02]\n",
      " [  2.96457969e-02]\n",
      " [  6.40060306e-02]\n",
      " [  5.76019064e-02]\n",
      " [  4.25460413e-02]\n",
      " [  6.69872761e-02]\n",
      " [  6.88263178e-02]\n",
      " [  6.65470585e-02]\n",
      " [  7.01146424e-02]\n",
      " [  6.67794943e-02]\n",
      " [  6.28458261e-02]\n",
      " [  5.81531003e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.86707050e-02]\n",
      " [  6.23669773e-02]\n",
      " [  5.84076084e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.84076084e-02]\n",
      " [  5.84076084e-02]\n",
      " [  6.81888834e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.88263178e-02]\n",
      " [  6.38299733e-02]\n",
      " [  6.23005889e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.06862290e-02]\n",
      " [  6.45858869e-02]\n",
      " [  1.00070592e-02]\n",
      " [  5.97948991e-02]\n",
      " [  6.07996881e-02]\n",
      " [  6.61006272e-02]\n",
      " [  6.60293400e-02]\n",
      " [  6.88619465e-02]\n",
      " [  6.71161339e-02]\n",
      " [  6.73671514e-02]\n",
      " [  6.58985972e-02]\n",
      " [  1.51180514e-13]\n",
      " [  5.83999753e-02]\n",
      " [  5.99432215e-02]\n",
      " [  1.16133224e-02]\n",
      " [  6.60540313e-02]\n",
      " [  6.60540313e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.83325604e-02]\n",
      " [  6.41357452e-02]\n",
      " [  6.83325604e-02]\n",
      " [  6.83325604e-02]\n",
      " [  6.18506745e-02]\n",
      " [  6.89737797e-02]\n",
      " [  7.08101764e-02]\n",
      " [  5.54831810e-02]\n",
      " [  3.43224145e-02]\n",
      " [  6.44912496e-02]\n",
      " [  6.21259026e-02]\n",
      " [  3.93889099e-02]\n",
      " [  6.99235275e-02]\n",
      " [  6.49508014e-02]\n",
      " [  4.96238545e-02]\n",
      " [  5.54646179e-02]\n",
      " [  6.35122061e-02]\n",
      " [  6.60743192e-02]\n",
      " [  5.01873530e-02]\n",
      " [  6.42935112e-02]\n",
      " [  5.81459627e-02]\n",
      " [  5.92200235e-02]\n",
      " [  6.15877770e-02]\n",
      " [  6.61006272e-02]\n",
      " [  6.41741231e-02]\n",
      " [  7.07874671e-02]\n",
      " [  6.45869672e-02]\n",
      " [  6.72330856e-02]\n",
      " [  6.45904243e-02]\n",
      " [  6.45904243e-02]\n",
      " [  6.99718222e-02]\n",
      " [  6.55595884e-02]\n",
      " [  7.08506778e-02]\n",
      " [  6.05404042e-02]\n",
      " [  6.60743192e-02]\n",
      " [  4.24225144e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.73671514e-02]\n",
      " [  5.19420467e-02]\n",
      " [  5.83445057e-02]\n",
      " [  6.21259026e-02]\n",
      " [  7.03140274e-02]\n",
      " [  5.77847585e-02]\n",
      " [  5.86470589e-02]\n",
      " [  5.96314445e-02]\n",
      " [  6.06348403e-02]\n",
      " [  6.05475046e-02]\n",
      " [  6.88263178e-02]\n",
      " [  5.96314445e-02]\n",
      " [  6.21115640e-02]\n",
      " [  5.70740700e-02]\n",
      " [  6.46032616e-02]\n",
      " [  6.17354587e-02]\n",
      " [  5.83461374e-02]\n",
      " [  6.46032616e-02]\n",
      " [  6.19884767e-02]\n",
      " [  6.49508014e-02]\n",
      " [  6.17354587e-02]\n",
      " [  5.31604700e-02]\n",
      " [  6.34848326e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.34848326e-02]\n",
      " [  6.34848326e-02]\n",
      " [  3.83067527e-04]\n",
      " [  5.55513874e-02]\n",
      " [  7.00577348e-02]\n",
      " [  1.67716088e-13]\n",
      " [  6.21259026e-02]\n",
      " [  3.51139270e-02]\n",
      " [  6.28548041e-02]\n",
      " [  6.81516901e-02]\n",
      " [  6.25486448e-02]\n",
      " [  6.46669865e-02]\n",
      " [  6.62752837e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.71530291e-02]\n",
      " [  6.36567622e-02]\n",
      " [  6.21259026e-02]\n",
      " [  1.20891702e-04]\n",
      " [  5.79470135e-02]\n",
      " [  6.17361777e-02]\n",
      " [  6.89737797e-02]\n",
      " [  6.89737797e-02]\n",
      " [  7.01670721e-02]\n",
      " [  6.63579479e-02]\n",
      " [  6.74232394e-02]\n",
      " [  6.88316450e-02]\n",
      " [  5.88891506e-02]\n",
      " [  7.38984123e-02]\n",
      " [  6.66426495e-02]\n",
      " [  6.92010000e-02]\n",
      " [  6.92010000e-02]\n",
      " [  6.92010000e-02]\n",
      " [  6.92010000e-02]\n",
      " [  6.92010000e-02]\n",
      " [  6.46669865e-02]\n",
      " [  6.28458261e-02]\n",
      " [  2.47366535e-22]\n",
      " [  5.44514582e-02]\n",
      " [  6.35260642e-02]\n",
      " [  6.35260642e-02]\n",
      " [  6.35260642e-02]\n",
      " [  6.12091683e-02]\n",
      " [  5.73069453e-02]\n",
      " [  6.17361777e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.56018837e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.86186610e-02]\n",
      " [  6.60540313e-02]\n",
      " [  6.29987791e-02]\n",
      " [  6.67076185e-02]\n",
      " [  6.02317639e-02]\n",
      " [  6.16297536e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.45828918e-02]\n",
      " [  6.21278584e-02]\n",
      " [  6.38255402e-02]\n",
      " [  6.46669865e-02]\n",
      " [  6.92502931e-02]\n",
      " [  6.09310716e-02]\n",
      " [  6.00255914e-02]\n",
      " [  5.96414208e-02]\n",
      " [  6.69748038e-02]\n",
      " [  5.97360134e-02]\n",
      " [  6.26947135e-02]\n",
      " [  1.78584958e-09]\n",
      " [  6.65063262e-02]\n",
      " [  5.06582577e-03]\n",
      " [  6.21259026e-02]\n",
      " [  2.92887390e-02]\n",
      " [  6.17361777e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.66855371e-02]\n",
      " [  6.21259026e-02]\n",
      " [  0.00000000e+00]\n",
      " [  5.83999753e-02]\n",
      " [  5.83999753e-02]\n",
      " [  5.83999753e-02]\n",
      " [  5.83999753e-02]\n",
      " [  5.83999753e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.83999753e-02]\n",
      " [  5.83999753e-02]\n",
      " [  6.89737797e-02]\n",
      " [  6.89737797e-02]\n",
      " [  6.91365823e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.73069453e-02]\n",
      " [  1.06409814e-12]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.81061819e-02]\n",
      " [  6.38448894e-02]\n",
      " [  4.23473641e-02]\n",
      " [  6.31877556e-02]\n",
      " [  1.80657388e-12]\n",
      " [  0.00000000e+00]\n",
      " [  5.77133521e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.28767610e-02]\n",
      " [  1.58675844e-04]\n",
      " [  6.28458261e-02]\n",
      " [  6.69748485e-02]\n",
      " [  5.35907149e-02]\n",
      " [  5.60224019e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.72703741e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.41741231e-02]\n",
      " [  6.34848326e-02]\n",
      " [  4.78732139e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.67149408e-02]\n",
      " [  5.73069453e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.73069453e-02]\n",
      " [  6.61006272e-02]\n",
      " [  5.80828600e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.00255914e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.33890629e-02]\n",
      " [  6.33226633e-02]\n",
      " [  6.19533397e-02]\n",
      " [  1.42529010e-04]\n",
      " [  6.89737797e-02]\n",
      " [  6.46669865e-02]\n",
      " [  6.35260642e-02]\n",
      " [  6.21259026e-02]\n",
      " [  1.76020851e-10]\n",
      " [  5.39246425e-02]\n",
      " [  5.83999753e-02]\n",
      " [  5.39246425e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.83999753e-02]\n",
      " [  5.73069453e-02]\n",
      " [  6.89737797e-02]\n",
      " [  6.29273653e-02]\n",
      " [  7.23796461e-07]\n",
      " [  5.83999753e-02]\n",
      " [  6.21259026e-02]\n",
      " [  4.46499214e-02]\n",
      " [  6.05186149e-02]\n",
      " [  5.50570861e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.11028634e-02]\n",
      " [  1.37799501e-03]\n",
      " [  5.83342239e-02]\n",
      " [  6.07334413e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.65818213e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  7.08971620e-02]\n",
      " [  6.46669865e-02]\n",
      " [  6.61006272e-02]\n",
      " [  4.93636616e-02]\n",
      " [  6.47905990e-02]\n",
      " [  7.87979960e-02]\n",
      " [  6.50392175e-02]\n",
      " [  6.50392175e-02]\n",
      " [  6.69748038e-02]\n",
      " [  6.69748038e-02]\n",
      " [  6.81198910e-02]\n",
      " [  6.81198910e-02]\n",
      " [  6.33787662e-02]\n",
      " [  5.95833212e-02]\n",
      " [  6.22583628e-02]\n",
      " [  6.27129003e-02]\n",
      " [  6.75767884e-02]\n",
      " [  5.75416125e-02]\n",
      " [  5.76619506e-02]\n",
      " [  6.63316920e-02]\n",
      " [  6.95853382e-02]\n",
      " [  6.20510727e-02]\n",
      " [  6.23487197e-02]\n",
      " [  7.07582384e-02]\n",
      " [  7.07582384e-02]\n",
      " [  3.18919147e-22]\n",
      " [  6.21259026e-02]\n",
      " [  6.68356791e-02]\n",
      " [  6.47278428e-02]\n",
      " [  6.47278428e-02]\n",
      " [  6.47278428e-02]\n",
      " [  6.47278428e-02]\n",
      " [  6.76383972e-02]\n",
      " [  6.47278428e-02]\n",
      " [  4.42345813e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.35941236e-02]\n",
      " [  5.87019734e-02]\n",
      " [  5.87019734e-02]\n",
      " [  5.56018837e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.35941236e-02]\n",
      " [  5.87019734e-02]\n",
      " [  6.89732730e-02]\n",
      " [  6.61006272e-02]\n",
      " [  5.31079993e-02]\n",
      " [  6.76698908e-02]\n",
      " [  6.21542782e-02]\n",
      " [  6.33072630e-02]\n",
      " [  6.69748038e-02]\n",
      " [  6.33787662e-02]\n",
      " [  5.79266101e-02]\n",
      " [  6.58967495e-02]\n",
      " [  7.76734227e-20]\n",
      " [  4.96319309e-02]\n",
      " [  5.12781851e-02]\n",
      " [  6.30168393e-02]\n",
      " [  6.21259026e-02]\n",
      " [  6.77925870e-02]\n",
      " [  6.95163831e-02]\n",
      " [  0.00000000e+00]\n",
      " [  7.08506778e-02]\n",
      " [  7.08506778e-02]\n",
      " [  6.73671514e-02]\n",
      " [  6.45647421e-02]\n",
      " [  6.45647421e-02]\n",
      " [  6.34521544e-02]\n",
      " [  6.41741231e-02]\n",
      " [  4.92147841e-02]\n",
      " [  5.35373427e-02]\n",
      " [  5.35373427e-02]\n",
      " [  5.87827638e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.24251685e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.60381487e-02]\n",
      " [  5.24251685e-02]\n",
      " [  6.35260642e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.39246425e-02]\n",
      " [  2.84574218e-02]\n",
      " [  5.88905923e-02]\n",
      " [  6.08199462e-02]\n",
      " [  6.57626092e-02]\n",
      " [  6.15623631e-02]\n",
      " [  6.74232394e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.21259026e-02]\n",
      " [  5.93037680e-02]\n",
      " [  5.52375242e-02]\n",
      " [  5.76306954e-02]\n",
      " [  5.40897436e-02]\n",
      " [  6.62752837e-02]\n",
      " [  5.65277077e-02]\n",
      " [  4.93242517e-02]\n",
      " [  7.07582384e-02]\n",
      " [  2.29174513e-02]\n",
      " [  6.05113208e-02]\n",
      " [  5.45940325e-02]\n",
      " [  5.45940325e-02]\n",
      " [  5.81525378e-02]\n",
      " [  5.03951237e-02]\n",
      " [  6.83334991e-02]\n",
      " [  6.47048950e-02]\n",
      " [  9.45451483e-03]\n",
      " [  6.55298010e-02]\n",
      " [  3.59000899e-02]\n",
      " [  5.03351688e-02]\n",
      " [  5.38131259e-02]\n",
      " [  5.78456186e-02]\n",
      " [  5.38131259e-02]\n",
      " [  1.05499569e-02]\n",
      " [  6.62752837e-02]\n",
      " [  5.38131259e-02]\n",
      " [  6.28458261e-02]\n",
      " [  5.94335273e-02]\n",
      " [  5.57287037e-02]\n",
      " [  5.76306060e-02]\n",
      " [  3.39803472e-02]\n",
      " [  5.84015362e-02]\n",
      " [  5.72915636e-02]\n",
      " [  5.61187305e-02]\n",
      " [  5.97209148e-02]\n",
      " [  5.92640899e-02]\n",
      " [  5.97209148e-02]\n",
      " [  5.39614409e-02]\n",
      " [  2.93969680e-02]\n",
      " [  5.11216745e-02]\n",
      " [  4.79153059e-02]\n",
      " [  4.89911512e-02]\n",
      " [  5.11216745e-02]\n",
      " [  5.11216745e-02]\n",
      " [  5.11216745e-02]\n",
      " [  5.11216745e-02]\n",
      " [  5.11216745e-02]\n",
      " [  4.79153059e-02]\n",
      " [  6.35260642e-02]\n",
      " [  4.89911512e-02]\n",
      " [  4.89911512e-02]\n",
      " [  5.94434983e-13]\n",
      " [  6.35260642e-02]\n",
      " [  6.35260642e-02]\n",
      " [  5.63304611e-02]\n",
      " [  6.41741231e-02]\n",
      " [  1.19547462e-37]\n",
      " [  4.73510474e-02]\n",
      " [  6.46669865e-02]\n",
      " [  5.34090921e-02]\n",
      " [  6.61006272e-02]\n",
      " [  6.00702241e-02]\n",
      " [  5.76306954e-02]\n",
      " [  5.66134639e-02]\n",
      " [  4.84155118e-02]\n",
      " [  5.30761927e-02]\n",
      " [  6.12300001e-02]\n",
      " [  6.62752837e-02]\n",
      " [  6.35260642e-02]\n",
      " [  5.69650643e-02]\n",
      " [  4.81876470e-02]\n",
      " [  5.66999204e-02]\n",
      " [  5.66999204e-02]\n",
      " [  5.66999204e-02]\n",
      " [  5.66999204e-02]\n",
      " [  5.66999204e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.80079965e-02]\n",
      " [  6.31184131e-02]\n",
      " [  6.47905990e-02]\n",
      " [  1.90533552e-04]\n",
      " [  7.30962455e-02]\n",
      " [  6.46199510e-02]\n",
      " [  7.10816830e-02]\n",
      " [  6.47905990e-02]\n",
      " [  9.29321842e-10]\n",
      " [  6.52072281e-02]\n",
      " [  5.49340099e-02]\n",
      " [  6.74232394e-02]\n",
      " [  3.58127288e-08]\n",
      " [  6.26947135e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.17361777e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.13328032e-02]\n",
      " [  6.73186257e-02]\n",
      " [  9.25303334e-10]\n",
      " [  7.10327253e-02]\n",
      " [  6.62752837e-02]\n",
      " [  6.95163831e-02]\n",
      " [  6.77736625e-02]\n",
      " [  1.99107853e-12]\n",
      " [  6.95163831e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.95163831e-02]\n",
      " [  6.69748038e-02]\n",
      " [  7.08506778e-02]\n",
      " [  5.74848689e-02]\n",
      " [  5.64112477e-02]\n",
      " [  5.64112477e-02]\n",
      " [  2.49309785e-04]\n",
      " [  5.71412183e-02]\n",
      " [  3.55455577e-02]\n",
      " [  5.63873909e-02]\n",
      " [  2.87096165e-02]\n",
      " [  6.20677173e-02]\n",
      " [  5.78617826e-02]\n",
      " [  2.57681124e-02]\n",
      " [  7.00936392e-02]\n",
      " [  4.05272096e-02]\n",
      " [  5.87958284e-02]\n",
      " [  6.57048896e-02]\n",
      " [  6.22285008e-02]\n",
      " [  4.05219533e-02]\n",
      " [  2.90496519e-05]\n",
      " [  6.37538210e-02]\n",
      " [  5.74530475e-02]\n",
      " [  6.28539026e-02]\n",
      " [  1.99807584e-02]\n",
      " [  4.16271426e-02]\n",
      " [  6.47905990e-02]\n",
      " [  5.08446731e-02]\n",
      " [  6.32018447e-02]\n",
      " [  6.81900159e-02]\n",
      " [  6.36535808e-02]\n",
      " [  5.15188798e-02]\n",
      " [  5.52538000e-02]\n",
      " [  3.89556959e-02]\n",
      " [  7.15849921e-02]\n",
      " [  5.52565232e-02]\n",
      " [  6.89747408e-02]\n",
      " [  5.73069453e-02]\n",
      " [  5.77646047e-02]\n",
      " [  7.18554854e-02]\n",
      " [  6.00118004e-02]\n",
      " [  4.93384600e-02]\n",
      " [  7.14628175e-02]\n",
      " [  3.55506092e-02]\n",
      " [  6.17361777e-02]\n",
      " [  1.10464813e-02]\n",
      " [  6.69652596e-02]\n",
      " [  6.17361777e-02]\n",
      " [  3.55506092e-02]\n",
      " [  7.06437603e-02]\n",
      " [  6.09567538e-02]\n",
      " [  6.17361777e-02]\n",
      " [  6.17361777e-02]\n",
      " [  3.60404216e-02]\n",
      " [  8.22109729e-02]\n",
      " [  3.60404216e-02]\n",
      " [  1.15524800e-02]\n",
      " [  4.23277542e-03]\n",
      " [  2.57485285e-02]\n",
      " [  3.60404216e-02]\n",
      " [  5.67289740e-02]\n",
      " [  6.27834573e-02]\n",
      " [  6.26898110e-02]\n",
      " [  6.73671514e-02]\n",
      " [  6.02322072e-02]\n",
      " [  3.55506092e-02]\n",
      " [  2.10281871e-02]\n",
      " [  4.92238216e-02]\n",
      " [  6.28458261e-02]\n",
      " [  3.55506092e-02]\n",
      " [  2.97790039e-02]\n",
      " [  3.22461799e-02]\n",
      " [  6.51505440e-02]\n",
      " [  6.25285283e-02]\n",
      " [  6.25285283e-02]\n",
      " [  4.00321529e-12]\n",
      " [  3.16228643e-02]\n",
      " [  6.93153664e-02]\n",
      " [  6.87830448e-02]\n",
      " [  3.96474451e-02]\n",
      " [  4.22129110e-02]\n",
      " [  6.46669865e-02]\n",
      " [  6.06658161e-02]\n",
      " [  6.61397353e-02]\n",
      " [  6.30158260e-02]\n",
      " [  1.92013606e-02]\n",
      " [  6.13837205e-02]\n",
      " [  6.02122769e-02]\n",
      " [  6.45904243e-02]\n",
      " [  6.25625700e-02]\n",
      " [  6.40055314e-02]\n",
      " [  6.23267256e-02]\n",
      " [  7.67940364e-11]\n",
      " [  6.83365166e-02]\n",
      " [  6.73425123e-02]\n",
      " [  5.19416332e-02]\n",
      " [  5.68001568e-02]\n",
      " [  4.53404635e-02]\n",
      " [  5.25727384e-02]\n",
      " [  6.22602552e-02]\n",
      " [  5.37119620e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.51144385e-02]\n",
      " [  5.31442910e-02]\n",
      " [  6.45835102e-02]\n",
      " [  6.20675646e-02]\n",
      " [  7.15912953e-02]\n",
      " [  6.60540313e-02]\n",
      " [  5.98469898e-02]\n",
      " [  5.59299253e-02]\n",
      " [  5.92529103e-02]\n",
      " [  6.26947135e-02]\n",
      " [  3.61079164e-02]\n",
      " [  3.61079164e-02]\n",
      " [  3.61079164e-02]\n",
      " [  3.33976038e-02]\n",
      " [  3.60854864e-02]\n",
      " [  3.55506092e-02]\n",
      " [  7.03140274e-02]\n",
      " [  6.53594211e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.04332574e-02]\n",
      " [  6.42626435e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.73186257e-02]\n",
      " [  3.60404216e-02]\n",
      " [  4.93017659e-02]\n",
      " [  6.25580102e-02]\n",
      " [  6.09576255e-02]\n",
      " [  7.91388303e-02]\n",
      " [  6.38516992e-02]\n",
      " [  5.67984208e-02]\n",
      " [  5.64036854e-02]\n",
      " [  5.77699132e-02]\n",
      " [  6.28458261e-02]\n",
      " [  6.44983947e-02]\n",
      " [  5.50949499e-02]\n",
      " [  6.57801032e-02]\n",
      " [  5.67466095e-02]\n",
      " [  3.60404216e-02]\n",
      " [  5.09456247e-02]\n",
      " [  6.50358945e-02]\n",
      " [  5.59455492e-02]\n",
      " [  5.86186610e-02]\n",
      " [  3.60404216e-02]\n",
      " [  5.54719418e-02]\n",
      " [  5.48119172e-02]\n",
      " [  3.60404216e-02]\n",
      " [  5.58522120e-02]\n",
      " [  5.51859103e-02]\n",
      " [  7.18121603e-02]\n",
      " [  6.95163831e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.23418838e-02]\n",
      " [  5.02672866e-02]\n",
      " [  7.18554854e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.82959110e-02]\n",
      " [  6.04224987e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.44912496e-02]\n",
      " [  5.94734959e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.73671514e-02]\n",
      " [  3.60404216e-02]\n",
      " [  5.48891574e-02]\n",
      " [  5.76361008e-02]\n",
      " [  5.77771440e-02]\n",
      " [  4.60684225e-02]\n",
      " [  6.53587654e-02]\n",
      " [  6.96353540e-02]\n",
      " [  5.32004386e-02]\n",
      " [  4.47839424e-02]\n",
      " [  5.55468202e-02]\n",
      " [  6.47905990e-02]\n",
      " [  3.57209370e-02]\n",
      " [  4.87054810e-02]\n",
      " [  5.63651323e-02]\n",
      " [  6.41353130e-02]\n",
      " [  6.47905990e-02]\n",
      " [  3.57209370e-02]\n",
      " [  5.77658005e-02]\n",
      " [  5.57449684e-02]\n",
      " [  6.47905990e-02]\n",
      " [  3.74808349e-02]\n",
      " [  6.10038973e-02]\n",
      " [  4.20458578e-02]\n",
      " [  6.31548390e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.60872608e-02]\n",
      " [  6.76763728e-02]\n",
      " [  5.26720807e-02]\n",
      " [  6.86125010e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.40817434e-02]\n",
      " [  4.47374657e-02]\n",
      " [  6.49367720e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.26947135e-02]\n",
      " [  5.17052487e-02]\n",
      " [  6.69748485e-02]\n",
      " [  3.57209370e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.47905990e-02]\n",
      " [  5.76387309e-02]\n",
      " [  4.96329889e-02]\n",
      " [  6.19866587e-02]\n",
      " [  3.57209370e-02]\n",
      " [  5.54829724e-02]\n",
      " [  5.61202429e-02]\n",
      " [  6.89662993e-02]\n",
      " [  3.57209370e-02]\n",
      " [  6.12515174e-02]\n",
      " [  5.39721176e-02]\n",
      " [  6.89662993e-02]\n",
      " [  3.57209370e-02]\n",
      " [  5.93612492e-02]\n",
      " [  4.96789925e-02]\n",
      " [  3.57209370e-02]\n",
      " [  6.26947135e-02]\n",
      " [  4.70017493e-02]\n",
      " [  3.74808349e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.26947135e-02]\n",
      " [  5.67687899e-02]\n",
      " [  7.69019872e-02]\n",
      " [  6.49400726e-02]\n",
      " [  5.52412197e-02]\n",
      " [  6.49593771e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.26947135e-02]\n",
      " [  5.29817976e-02]\n",
      " [  6.50392175e-02]\n",
      " [  5.79925589e-02]\n",
      " [  5.56580350e-02]\n",
      " [  6.58429265e-02]\n",
      " [  6.66964874e-02]\n",
      " [  6.26947135e-02]\n",
      " [  6.26947135e-02]\n",
      " [  5.83829433e-02]\n",
      " [  6.73186257e-02]\n",
      " [  3.74808349e-02]\n",
      " [  6.49571717e-02]\n",
      " [  3.09925795e-01]\n",
      " [  5.98455705e-02]\n",
      " [  3.74808349e-02]\n",
      " [  6.26947135e-02]\n",
      " [  4.82500084e-02]\n",
      " [  6.73566163e-02]\n",
      " [  6.26947135e-02]\n",
      " [  5.76839522e-02]\n",
      " [  6.79833293e-02]\n",
      " [  6.65890425e-02]\n",
      " [  8.46463218e-02]\n",
      " [  6.41419291e-02]\n",
      " [  6.72493428e-02]\n",
      " [  6.61478862e-02]\n",
      " [  6.61478862e-02]\n",
      " [  4.88617383e-02]\n",
      " [  6.73186257e-02]\n",
      " [  7.58442432e-02]\n",
      " [  6.28458261e-02]\n",
      " [  6.15524612e-02]\n",
      " [  2.70829052e-02]\n",
      " [  1.03931986e-02]\n",
      " [  7.31101930e-02]\n",
      " [  1.21812280e-02]\n",
      " [  4.82582934e-02]\n",
      " [  5.63779809e-02]\n",
      " [  6.33329004e-02]\n",
      " [  6.11221828e-02]\n",
      " [  2.50844744e-12]\n",
      " [  4.83787572e-03]\n",
      " [  6.67444095e-02]\n",
      " [  6.74787760e-02]\n",
      " [  6.19929172e-02]\n",
      " [  6.69748038e-02]\n",
      " [  6.59769848e-02]\n",
      " [  6.47905990e-02]\n",
      " [  7.50301331e-02]\n",
      " [  6.19533397e-02]\n",
      " [  8.46015960e-02]\n",
      " [  6.50592968e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.61006272e-02]\n",
      " [  6.21531866e-02]\n",
      " [  6.46669865e-02]\n",
      " [  6.60540313e-02]\n",
      " [  6.61478862e-02]\n",
      " [  6.44000247e-02]\n",
      " [  6.89737797e-02]\n",
      " [  6.89737797e-02]\n",
      " [  6.50392175e-02]\n",
      " [  6.24640360e-02]\n",
      " [  6.67268708e-02]\n",
      " [  6.06363006e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.76383972e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.47730976e-02]\n",
      " [  6.79344535e-02]\n",
      " [  6.61006272e-02]\n",
      " [  6.61478862e-02]\n",
      " [  6.50392175e-02]\n",
      " [  6.98352158e-02]\n",
      " [  6.55338392e-02]\n",
      " [  6.83334991e-02]\n",
      " [  6.47905990e-02]\n",
      " [  6.33787662e-02]\n",
      " [  6.85392544e-02]\n",
      " [  5.04863001e-02]\n",
      " [  5.92445023e-02]\n",
      " [  7.87912309e-02]\n",
      " [  2.44420376e-02]\n",
      " [  5.60232475e-02]\n",
      " [  6.46669865e-02]\n",
      " [  5.91834495e-03]\n",
      " [  6.73186257e-02]\n",
      " [  1.63795240e-02]\n",
      " [  5.68780564e-02]\n",
      " [  5.30414023e-02]\n",
      " [  4.57024314e-02]\n",
      " [  4.37408344e-05]\n",
      " [  3.45286019e-02]\n",
      " [  6.35260642e-02]\n",
      " [  6.46109134e-02]\n",
      " [  6.26947135e-02]\n",
      " [  6.26947135e-02]\n",
      " [  6.26947135e-02]\n",
      " [  6.46669865e-02]\n",
      " [  3.45286019e-02]\n",
      " [  5.80583960e-02]\n",
      " [  6.26947135e-02]\n",
      " [  6.19533397e-02]\n",
      " [  6.28473908e-02]\n",
      " [  6.62693605e-02]\n",
      " [  6.73186257e-02]\n",
      " [  6.34261146e-02]\n",
      " [  6.00804947e-02]\n",
      " [  6.02954291e-02]\n",
      " [  5.93333915e-02]\n",
      " [  6.58959746e-02]\n",
      " [  1.15224530e-05]\n",
      " [  6.19296357e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.66395500e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.17361777e-02]\n",
      " [  3.60404216e-02]\n",
      " [  3.60404216e-02]\n",
      " [  5.39277941e-02]\n",
      " [  6.60540313e-02]\n",
      " [  4.47668619e-02]\n",
      " [  6.17361777e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.27236813e-02]\n",
      " [  6.17361777e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.48232400e-02]\n",
      " [  3.60404216e-02]\n",
      " [  7.36715198e-02]\n",
      " [  6.80721924e-02]\n",
      " [  3.60404216e-02]\n",
      " [  5.43166287e-02]\n",
      " [  3.60404216e-02]\n",
      " [  3.60404216e-02]\n",
      " [  5.88059314e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.23370409e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.73671514e-02]\n",
      " [  6.17361777e-02]\n",
      " [  6.17361777e-02]\n",
      " [  5.83999753e-02]\n",
      " [  5.70143685e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.48404807e-02]\n",
      " [  6.47905990e-02]\n",
      " [  5.39958291e-02]\n",
      " [  6.17361777e-02]\n",
      " [  6.49918094e-02]\n",
      " [  3.60404216e-02]\n",
      " [  3.60404216e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.60193861e-02]\n",
      " [  6.17361777e-02]\n",
      " [  5.59596866e-02]\n",
      " [  6.17361777e-02]\n",
      " [  3.60404216e-02]\n",
      " [  6.00008555e-02]\n",
      " [  5.55015132e-02]\n",
      " [  1.65890865e-02]\n",
      " [  5.29962480e-02]\n",
      " [  3.60404216e-02]]\n"
     ]
    }
   ],
   "source": [
    "print predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method predict_generator in module keras.models:\n",
      "\n",
      "predict_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False) unbound keras.models.Sequential method\n",
      "    Generates predictions for the input samples from a data generator.\n",
      "    The generator should return the same kind of data as accepted by\n",
      "    `predict_on_batch`.\n",
      "    \n",
      "    # Arguments\n",
      "        generator: generator yielding batches of input samples.\n",
      "        val_samples: total number of samples to generate from `generator`\n",
      "            before returning.\n",
      "        max_q_size: maximum size for the generator queue\n",
      "        nb_worker: maximum number of processes to spin up\n",
      "        pickle_safe: if True, use process based threading. Note that because\n",
      "            this implementation relies on multiprocessing, you should not pass non\n",
      "            non picklable arguments to the generator as they can't be passed\n",
      "            easily to children processes.\n",
      "    \n",
      "    # Returns\n",
      "        A Numpy array of predictions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Sequential.predict_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(myGenerator(), samples_per_epoch = 60000, nb_epoch = 2, verbose=2, show_accuracy=True, callbacks=[], validation_data=None, class_weight=None, nb_worker=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18550, 151, 704)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_swp = np.swapaxes(X,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18550"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_swp.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndense = Dense(1, activation = \"sigmoid\", kernel_initializer = \"ones\")\\n\\nop1 = dense(ip_shape1)\\nop2 = dense(ip_shape2)\\n\\nmerge_layer = keras.layers.concatenate([op1, op2])\\npredictions = Dense(1, activation=\\'sigmoid\\')(merge_layer)\\n\\nmodel = Model(inputs=[ip_shape1, ip_shape2], outputs=predictions)\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, LSTM, Dense, merge\n",
    "from keras.models import Model\n",
    "#dim1 = len(features[0][0])\n",
    "#dim2 = len(features)\n",
    "dim1 = X.shape[2]\n",
    "\n",
    "dense = Dense(100, activation = \"relu\", init=\"normal\")\n",
    "ip_shapes = []\n",
    "op_shapes = []\n",
    "for i in range(X.shape[1]):\n",
    "    ip_shape = ( Input(shape=(dim1,)) )\n",
    "    ip_shapes.append(ip_shape)\n",
    "    op_shapes.append( dense(ip_shape))\n",
    "\n",
    "merged_vector = merge(op_shapes, mode='ave', concat_axis=-1)\n",
    "\n",
    "hidden1 = Dense(100, activation = \"relu\", init=\"normal\")(merged_vector)\n",
    "hidden2 = Dense(100, activation = \"relu\", init=\"normal\")(hidden1)\n",
    "hidden3 = Dense(100, activation = \"relu\", init=\"normal\")(hidden2)\n",
    "hidden4 = Dense(100, activation = \"relu\", init=\"normal\")(hidden3)\n",
    "# and add a logistic regression on top\n",
    "predictions = Dense(1, activation='sigmoid')(hidden4)\n",
    "\n",
    "# we define a trainable model linking the\n",
    "# tweet inputs to the predictions\n",
    "model = Model(input = ip_shapes, output=predictions)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.0), \n",
    "              metrics=['accuracy', auc])\n",
    "\n",
    "\"\"\"\n",
    "dense = Dense(1, activation = \"sigmoid\", kernel_initializer = \"ones\")\n",
    "\n",
    "op1 = dense(ip_shape1)\n",
    "op2 = dense(ip_shape2)\n",
    "\n",
    "merge_layer = keras.layers.concatenate([op1, op2])\n",
    "predictions = Dense(1, activation='sigmoid')(merge_layer)\n",
    "\n",
    "model = Model(inputs=[ip_shape1, ip_shape2], outputs=predictions)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_385 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_386 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_387 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_388 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_389 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_390 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_391 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_392 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_393 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_394 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_395 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_396 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_397 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_398 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_399 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_400 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_401 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_402 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_403 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_404 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_405 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_406 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_407 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_408 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_409 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_410 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_411 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_412 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_413 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_414 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_415 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_416 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_417 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_418 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_419 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_420 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_421 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_422 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_423 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_424 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_425 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_426 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_427 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_428 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_429 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_430 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_431 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_432 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_433 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_434 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_435 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_436 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_437 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_438 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_439 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_440 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_441 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_442 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_443 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_444 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_445 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_446 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_447 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_448 (InputLayer)           (None, 1661)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_30 (Dense)                 (None, 100)           166200      input_385[0][0]                  \n",
      "                                                                   input_386[0][0]                  \n",
      "                                                                   input_387[0][0]                  \n",
      "                                                                   input_388[0][0]                  \n",
      "                                                                   input_389[0][0]                  \n",
      "                                                                   input_390[0][0]                  \n",
      "                                                                   input_391[0][0]                  \n",
      "                                                                   input_392[0][0]                  \n",
      "                                                                   input_393[0][0]                  \n",
      "                                                                   input_394[0][0]                  \n",
      "                                                                   input_395[0][0]                  \n",
      "                                                                   input_396[0][0]                  \n",
      "                                                                   input_397[0][0]                  \n",
      "                                                                   input_398[0][0]                  \n",
      "                                                                   input_399[0][0]                  \n",
      "                                                                   input_400[0][0]                  \n",
      "                                                                   input_401[0][0]                  \n",
      "                                                                   input_402[0][0]                  \n",
      "                                                                   input_403[0][0]                  \n",
      "                                                                   input_404[0][0]                  \n",
      "                                                                   input_405[0][0]                  \n",
      "                                                                   input_406[0][0]                  \n",
      "                                                                   input_407[0][0]                  \n",
      "                                                                   input_408[0][0]                  \n",
      "                                                                   input_409[0][0]                  \n",
      "                                                                   input_410[0][0]                  \n",
      "                                                                   input_411[0][0]                  \n",
      "                                                                   input_412[0][0]                  \n",
      "                                                                   input_413[0][0]                  \n",
      "                                                                   input_414[0][0]                  \n",
      "                                                                   input_415[0][0]                  \n",
      "                                                                   input_416[0][0]                  \n",
      "                                                                   input_417[0][0]                  \n",
      "                                                                   input_418[0][0]                  \n",
      "                                                                   input_419[0][0]                  \n",
      "                                                                   input_420[0][0]                  \n",
      "                                                                   input_421[0][0]                  \n",
      "                                                                   input_422[0][0]                  \n",
      "                                                                   input_423[0][0]                  \n",
      "                                                                   input_424[0][0]                  \n",
      "                                                                   input_425[0][0]                  \n",
      "                                                                   input_426[0][0]                  \n",
      "                                                                   input_427[0][0]                  \n",
      "                                                                   input_428[0][0]                  \n",
      "                                                                   input_429[0][0]                  \n",
      "                                                                   input_430[0][0]                  \n",
      "                                                                   input_431[0][0]                  \n",
      "                                                                   input_432[0][0]                  \n",
      "                                                                   input_433[0][0]                  \n",
      "                                                                   input_434[0][0]                  \n",
      "                                                                   input_435[0][0]                  \n",
      "                                                                   input_436[0][0]                  \n",
      "                                                                   input_437[0][0]                  \n",
      "                                                                   input_438[0][0]                  \n",
      "                                                                   input_439[0][0]                  \n",
      "                                                                   input_440[0][0]                  \n",
      "                                                                   input_441[0][0]                  \n",
      "                                                                   input_442[0][0]                  \n",
      "                                                                   input_443[0][0]                  \n",
      "                                                                   input_444[0][0]                  \n",
      "                                                                   input_445[0][0]                  \n",
      "                                                                   input_446[0][0]                  \n",
      "                                                                   input_447[0][0]                  \n",
      "                                                                   input_448[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_7 (Merge)                  (None, 100)           0           dense_30[0][0]                   \n",
      "                                                                   dense_30[1][0]                   \n",
      "                                                                   dense_30[2][0]                   \n",
      "                                                                   dense_30[3][0]                   \n",
      "                                                                   dense_30[4][0]                   \n",
      "                                                                   dense_30[5][0]                   \n",
      "                                                                   dense_30[6][0]                   \n",
      "                                                                   dense_30[7][0]                   \n",
      "                                                                   dense_30[8][0]                   \n",
      "                                                                   dense_30[9][0]                   \n",
      "                                                                   dense_30[10][0]                  \n",
      "                                                                   dense_30[11][0]                  \n",
      "                                                                   dense_30[12][0]                  \n",
      "                                                                   dense_30[13][0]                  \n",
      "                                                                   dense_30[14][0]                  \n",
      "                                                                   dense_30[15][0]                  \n",
      "                                                                   dense_30[16][0]                  \n",
      "                                                                   dense_30[17][0]                  \n",
      "                                                                   dense_30[18][0]                  \n",
      "                                                                   dense_30[19][0]                  \n",
      "                                                                   dense_30[20][0]                  \n",
      "                                                                   dense_30[21][0]                  \n",
      "                                                                   dense_30[22][0]                  \n",
      "                                                                   dense_30[23][0]                  \n",
      "                                                                   dense_30[24][0]                  \n",
      "                                                                   dense_30[25][0]                  \n",
      "                                                                   dense_30[26][0]                  \n",
      "                                                                   dense_30[27][0]                  \n",
      "                                                                   dense_30[28][0]                  \n",
      "                                                                   dense_30[29][0]                  \n",
      "                                                                   dense_30[30][0]                  \n",
      "                                                                   dense_30[31][0]                  \n",
      "                                                                   dense_30[32][0]                  \n",
      "                                                                   dense_30[33][0]                  \n",
      "                                                                   dense_30[34][0]                  \n",
      "                                                                   dense_30[35][0]                  \n",
      "                                                                   dense_30[36][0]                  \n",
      "                                                                   dense_30[37][0]                  \n",
      "                                                                   dense_30[38][0]                  \n",
      "                                                                   dense_30[39][0]                  \n",
      "                                                                   dense_30[40][0]                  \n",
      "                                                                   dense_30[41][0]                  \n",
      "                                                                   dense_30[42][0]                  \n",
      "                                                                   dense_30[43][0]                  \n",
      "                                                                   dense_30[44][0]                  \n",
      "                                                                   dense_30[45][0]                  \n",
      "                                                                   dense_30[46][0]                  \n",
      "                                                                   dense_30[47][0]                  \n",
      "                                                                   dense_30[48][0]                  \n",
      "                                                                   dense_30[49][0]                  \n",
      "                                                                   dense_30[50][0]                  \n",
      "                                                                   dense_30[51][0]                  \n",
      "                                                                   dense_30[52][0]                  \n",
      "                                                                   dense_30[53][0]                  \n",
      "                                                                   dense_30[54][0]                  \n",
      "                                                                   dense_30[55][0]                  \n",
      "                                                                   dense_30[56][0]                  \n",
      "                                                                   dense_30[57][0]                  \n",
      "                                                                   dense_30[58][0]                  \n",
      "                                                                   dense_30[59][0]                  \n",
      "                                                                   dense_30[60][0]                  \n",
      "                                                                   dense_30[61][0]                  \n",
      "                                                                   dense_30[62][0]                  \n",
      "                                                                   dense_30[63][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 100)           10100       merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_32 (Dense)                 (None, 100)           10100       dense_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_33 (Dense)                 (None, 100)           10100       dense_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_34 (Dense)                 (None, 100)           10100       dense_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_35 (Dense)                 (None, 1)             101         dense_34[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 206,701\n",
      "Trainable params: 206,701\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_swp = np.swapaxes(X_train,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for i in range(X_train_swp.shape[0]):\n",
    "    inputs.append(X_train_swp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.2867 - acc: 0.9354 - auc: 0.4795    \n",
      "Epoch 2/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.2317 - acc: 0.9391 - auc: 0.5060    \n",
      "Epoch 3/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.2285 - acc: 0.9391 - auc: 0.5221    \n",
      "Epoch 4/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.2251 - acc: 0.9391 - auc: 0.5426    \n",
      "Epoch 5/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.2189 - acc: 0.9391 - auc: 0.5707    \n",
      "Epoch 6/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.2163 - acc: 0.9391 - auc: 0.5932    \n",
      "Epoch 7/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.2155 - acc: 0.9391 - auc: 0.6112    \n",
      "Epoch 8/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.2130 - acc: 0.9391 - auc: 0.6256    \n",
      "Epoch 9/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.2121 - acc: 0.9391 - auc: 0.6378    \n",
      "Epoch 10/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.2095 - acc: 0.9392 - auc: 0.6468    \n",
      "Epoch 11/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.2081 - acc: 0.9391 - auc: 0.6554    \n",
      "Epoch 12/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.2072 - acc: 0.9390 - auc: 0.6629    \n",
      "Epoch 13/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.2070 - acc: 0.9391 - auc: 0.6690    \n",
      "Epoch 14/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.2045 - acc: 0.9393 - auc: 0.6749    \n",
      "Epoch 15/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.2045 - acc: 0.9391 - auc: 0.6795    \n",
      "Epoch 16/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.2030 - acc: 0.9393 - auc: 0.6842    \n",
      "Epoch 17/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.2030 - acc: 0.9389 - auc: 0.6885    \n",
      "Epoch 18/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.2018 - acc: 0.9392 - auc: 0.6923    \n",
      "Epoch 19/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.2020 - acc: 0.9391 - auc: 0.6960    \n",
      "Epoch 20/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1990 - acc: 0.9394 - auc: 0.6993    \n",
      "Epoch 21/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1978 - acc: 0.9395 - auc: 0.7026    \n",
      "Epoch 22/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1957 - acc: 0.9403 - auc: 0.7065    \n",
      "Epoch 23/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1951 - acc: 0.9398 - auc: 0.7098    \n",
      "Epoch 24/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1945 - acc: 0.9398 - auc: 0.7129    \n",
      "Epoch 25/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1932 - acc: 0.9401 - auc: 0.7161    \n",
      "Epoch 26/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1930 - acc: 0.9402 - auc: 0.7194    \n",
      "Epoch 27/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1911 - acc: 0.9408 - auc: 0.7222    \n",
      "Epoch 28/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1900 - acc: 0.9408 - auc: 0.7254    \n",
      "Epoch 29/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1877 - acc: 0.9405 - auc: 0.7283    \n",
      "Epoch 30/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1868 - acc: 0.9412 - auc: 0.7313    \n",
      "Epoch 31/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1866 - acc: 0.9411 - auc: 0.7342    \n",
      "Epoch 32/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1836 - acc: 0.9411 - auc: 0.7370    \n",
      "Epoch 33/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1847 - acc: 0.9417 - auc: 0.7396    \n",
      "Epoch 34/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1832 - acc: 0.9408 - auc: 0.7422    \n",
      "Epoch 35/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1836 - acc: 0.9415 - auc: 0.7449    \n",
      "Epoch 36/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1806 - acc: 0.9429 - auc: 0.7470    \n",
      "Epoch 37/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1802 - acc: 0.9421 - auc: 0.7493    \n",
      "Epoch 38/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1778 - acc: 0.9428 - auc: 0.7516    \n",
      "Epoch 39/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1761 - acc: 0.9439 - auc: 0.7539    \n",
      "Epoch 40/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1759 - acc: 0.9429 - auc: 0.7563    \n",
      "Epoch 41/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1743 - acc: 0.9441 - auc: 0.7584    \n",
      "Epoch 42/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1736 - acc: 0.9445 - auc: 0.7604    \n",
      "Epoch 43/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1715 - acc: 0.9443 - auc: 0.7626    \n",
      "Epoch 44/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1715 - acc: 0.9443 - auc: 0.7648    \n",
      "Epoch 45/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1708 - acc: 0.9455 - auc: 0.7667    \n",
      "Epoch 46/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1686 - acc: 0.9466 - auc: 0.7685    \n",
      "Epoch 47/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1663 - acc: 0.9469 - auc: 0.7705    \n",
      "Epoch 48/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1678 - acc: 0.9463 - auc: 0.7725    \n",
      "Epoch 49/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1644 - acc: 0.9486 - auc: 0.7743    \n",
      "Epoch 50/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1645 - acc: 0.9488 - auc: 0.7761    \n",
      "Epoch 51/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1628 - acc: 0.9496 - auc: 0.7778    \n",
      "Epoch 52/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1645 - acc: 0.9480 - auc: 0.7794    \n",
      "Epoch 53/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1617 - acc: 0.9492 - auc: 0.7810    \n",
      "Epoch 54/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1614 - acc: 0.9494 - auc: 0.7826    \n",
      "Epoch 55/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1596 - acc: 0.9498 - auc: 0.7842    \n",
      "Epoch 56/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1602 - acc: 0.9503 - auc: 0.7856    \n",
      "Epoch 57/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1603 - acc: 0.9505 - auc: 0.7871    \n",
      "Epoch 58/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1591 - acc: 0.9501 - auc: 0.7885    \n",
      "Epoch 59/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1592 - acc: 0.9514 - auc: 0.7898    \n",
      "Epoch 60/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1573 - acc: 0.9507 - auc: 0.7912    \n",
      "Epoch 61/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1599 - acc: 0.9517 - auc: 0.7925    \n",
      "Epoch 62/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1584 - acc: 0.9510 - auc: 0.7939    \n",
      "Epoch 63/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1568 - acc: 0.9519 - auc: 0.7951    \n",
      "Epoch 64/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1578 - acc: 0.9519 - auc: 0.7962    \n",
      "Epoch 65/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1535 - acc: 0.9527 - auc: 0.7974    \n",
      "Epoch 66/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1529 - acc: 0.9526 - auc: 0.7987    \n",
      "Epoch 67/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1513 - acc: 0.9530 - auc: 0.7999    \n",
      "Epoch 68/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1544 - acc: 0.9518 - auc: 0.8011    \n",
      "Epoch 69/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1502 - acc: 0.9539 - auc: 0.8022    \n",
      "Epoch 70/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1527 - acc: 0.9525 - auc: 0.8034    \n",
      "Epoch 71/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1542 - acc: 0.9517 - auc: 0.8044    \n",
      "Epoch 72/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1527 - acc: 0.9531 - auc: 0.8055    \n",
      "Epoch 73/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1528 - acc: 0.9530 - auc: 0.8065    \n",
      "Epoch 74/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1502 - acc: 0.9550 - auc: 0.8075    \n",
      "Epoch 75/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1499 - acc: 0.9533 - auc: 0.8085    \n",
      "Epoch 76/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1498 - acc: 0.9536 - auc: 0.8094    \n",
      "Epoch 77/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1506 - acc: 0.9543 - auc: 0.8104    \n",
      "Epoch 78/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1491 - acc: 0.9536 - auc: 0.8113    \n",
      "Epoch 79/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1476 - acc: 0.9546 - auc: 0.8122    \n",
      "Epoch 80/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1481 - acc: 0.9542 - auc: 0.8131    \n",
      "Epoch 81/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1482 - acc: 0.9542 - auc: 0.8141    \n",
      "Epoch 82/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1509 - acc: 0.9538 - auc: 0.8149    \n",
      "Epoch 83/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1498 - acc: 0.9538 - auc: 0.8157    \n",
      "Epoch 84/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1499 - acc: 0.9542 - auc: 0.8164    \n",
      "Epoch 85/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1504 - acc: 0.9550 - auc: 0.8173    \n",
      "Epoch 86/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1511 - acc: 0.9544 - auc: 0.8180    \n",
      "Epoch 87/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1495 - acc: 0.9551 - auc: 0.8188    \n",
      "Epoch 88/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1515 - acc: 0.9537 - auc: 0.8195    \n",
      "Epoch 89/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1496 - acc: 0.9551 - auc: 0.8202    \n",
      "Epoch 90/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1477 - acc: 0.9554 - auc: 0.8209    \n",
      "Epoch 91/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1493 - acc: 0.9539 - auc: 0.8217    \n",
      "Epoch 92/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1465 - acc: 0.9553 - auc: 0.8224    \n",
      "Epoch 93/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1475 - acc: 0.9547 - auc: 0.8231    \n",
      "Epoch 94/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1470 - acc: 0.9551 - auc: 0.8238    \n",
      "Epoch 95/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1474 - acc: 0.9558 - auc: 0.8245    \n",
      "Epoch 96/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1457 - acc: 0.9563 - auc: 0.8252    \n",
      "Epoch 97/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1477 - acc: 0.9551 - auc: 0.8259    \n",
      "Epoch 98/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1481 - acc: 0.9552 - auc: 0.8265    \n",
      "Epoch 99/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1516 - acc: 0.9540 - auc: 0.8271    \n",
      "Epoch 100/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1473 - acc: 0.9559 - auc: 0.8276    \n",
      "Epoch 101/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1443 - acc: 0.9563 - auc: 0.8283    \n",
      "Epoch 102/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1443 - acc: 0.9559 - auc: 0.8289    \n",
      "Epoch 103/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1442 - acc: 0.9568 - auc: 0.8295    \n",
      "Epoch 104/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1463 - acc: 0.9556 - auc: 0.8301    \n",
      "Epoch 105/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1546 - acc: 0.9544 - auc: 0.8306    \n",
      "Epoch 106/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1493 - acc: 0.9557 - auc: 0.8311    \n",
      "Epoch 107/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1465 - acc: 0.9562 - auc: 0.8316    \n",
      "Epoch 108/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1447 - acc: 0.9563 - auc: 0.8322    \n",
      "Epoch 109/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1483 - acc: 0.9546 - auc: 0.8327    \n",
      "Epoch 110/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1447 - acc: 0.9563 - auc: 0.8332    \n",
      "Epoch 111/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1434 - acc: 0.9572 - auc: 0.8337    \n",
      "Epoch 112/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1423 - acc: 0.9564 - auc: 0.8343    \n",
      "Epoch 113/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1391 - acc: 0.9574 - auc: 0.8348    \n",
      "Epoch 114/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1401 - acc: 0.9559 - auc: 0.8353    \n",
      "Epoch 115/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1394 - acc: 0.9563 - auc: 0.8359    \n",
      "Epoch 116/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1384 - acc: 0.9571 - auc: 0.8365    \n",
      "Epoch 117/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1394 - acc: 0.9564 - auc: 0.8369    \n",
      "Epoch 118/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1384 - acc: 0.9574 - auc: 0.8374    \n",
      "Epoch 119/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1384 - acc: 0.9570 - auc: 0.8380    \n",
      "Epoch 120/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1400 - acc: 0.9558 - auc: 0.8385    \n",
      "Epoch 121/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1383 - acc: 0.9570 - auc: 0.8390    \n",
      "Epoch 122/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1370 - acc: 0.9572 - auc: 0.8395    \n",
      "Epoch 123/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1370 - acc: 0.9571 - auc: 0.8400    \n",
      "Epoch 124/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1414 - acc: 0.9558 - auc: 0.8405    \n",
      "Epoch 125/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1381 - acc: 0.9567 - auc: 0.8409    \n",
      "Epoch 126/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1379 - acc: 0.9572 - auc: 0.8414    \n",
      "Epoch 127/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1367 - acc: 0.9576 - auc: 0.8419    \n",
      "Epoch 128/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1385 - acc: 0.9572 - auc: 0.8423    \n",
      "Epoch 129/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1381 - acc: 0.9568 - auc: 0.8427    \n",
      "Epoch 130/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1391 - acc: 0.9567 - auc: 0.8432    \n",
      "Epoch 131/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1370 - acc: 0.9573 - auc: 0.8436    \n",
      "Epoch 132/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1382 - acc: 0.9568 - auc: 0.8441    \n",
      "Epoch 133/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1381 - acc: 0.9567 - auc: 0.8445    \n",
      "Epoch 134/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1358 - acc: 0.9571 - auc: 0.8449    \n",
      "Epoch 135/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1349 - acc: 0.9582 - auc: 0.8453    \n",
      "Epoch 136/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1390 - acc: 0.9564 - auc: 0.8458    \n",
      "Epoch 137/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1352 - acc: 0.9582 - auc: 0.8462    \n",
      "Epoch 138/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1366 - acc: 0.9579 - auc: 0.8466    \n",
      "Epoch 139/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1352 - acc: 0.9580 - auc: 0.8470    \n",
      "Epoch 140/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1367 - acc: 0.9576 - auc: 0.8473    \n",
      "Epoch 141/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1375 - acc: 0.9568 - auc: 0.8477    \n",
      "Epoch 142/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1362 - acc: 0.9584 - auc: 0.8481    \n",
      "Epoch 143/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1398 - acc: 0.9576 - auc: 0.8485    \n",
      "Epoch 144/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1376 - acc: 0.9567 - auc: 0.8488    \n",
      "Epoch 145/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1364 - acc: 0.9570 - auc: 0.8492    \n",
      "Epoch 146/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1350 - acc: 0.9580 - auc: 0.8496    \n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17563/17563 [==============================] - 13s - loss: 0.1362 - acc: 0.9585 - auc: 0.8499    \n",
      "Epoch 148/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1342 - acc: 0.9583 - auc: 0.8503    \n",
      "Epoch 149/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1406 - acc: 0.9564 - auc: 0.8506    \n",
      "Epoch 150/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1354 - acc: 0.9577 - auc: 0.8510    \n",
      "Epoch 151/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1344 - acc: 0.9582 - auc: 0.8513    \n",
      "Epoch 152/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1344 - acc: 0.9576 - auc: 0.8517    \n",
      "Epoch 153/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1334 - acc: 0.9582 - auc: 0.8520    \n",
      "Epoch 154/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1334 - acc: 0.9591 - auc: 0.8524    \n",
      "Epoch 155/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1352 - acc: 0.9583 - auc: 0.8527    \n",
      "Epoch 156/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1358 - acc: 0.9576 - auc: 0.8531    \n",
      "Epoch 157/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1340 - acc: 0.9582 - auc: 0.8534    \n",
      "Epoch 158/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1330 - acc: 0.9581 - auc: 0.8538    \n",
      "Epoch 159/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1328 - acc: 0.9587 - auc: 0.8541    \n",
      "Epoch 160/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1313 - acc: 0.9586 - auc: 0.8544    \n",
      "Epoch 161/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1332 - acc: 0.9584 - auc: 0.8548    \n",
      "Epoch 162/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1331 - acc: 0.9587 - auc: 0.8551    \n",
      "Epoch 163/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1330 - acc: 0.9578 - auc: 0.8554    \n",
      "Epoch 164/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1317 - acc: 0.9588 - auc: 0.8557    \n",
      "Epoch 165/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1333 - acc: 0.9583 - auc: 0.8560    \n",
      "Epoch 166/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1350 - acc: 0.9575 - auc: 0.8564    \n",
      "Epoch 167/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1334 - acc: 0.9576 - auc: 0.8567    \n",
      "Epoch 168/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1338 - acc: 0.9579 - auc: 0.8569    \n",
      "Epoch 169/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1358 - acc: 0.9576 - auc: 0.8572    \n",
      "Epoch 170/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1326 - acc: 0.9580 - auc: 0.8575    \n",
      "Epoch 171/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1326 - acc: 0.9583 - auc: 0.8578    \n",
      "Epoch 172/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1312 - acc: 0.9584 - auc: 0.8581    \n",
      "Epoch 173/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1312 - acc: 0.9588 - auc: 0.8584    \n",
      "Epoch 174/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1331 - acc: 0.9580 - auc: 0.8587    \n",
      "Epoch 175/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1316 - acc: 0.9586 - auc: 0.8589    \n",
      "Epoch 176/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1306 - acc: 0.9587 - auc: 0.8592    \n",
      "Epoch 177/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1305 - acc: 0.9591 - auc: 0.8595    \n",
      "Epoch 178/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1326 - acc: 0.9589 - auc: 0.8598    \n",
      "Epoch 179/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1337 - acc: 0.9580 - auc: 0.8601    \n",
      "Epoch 180/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1337 - acc: 0.9580 - auc: 0.8603    \n",
      "Epoch 181/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1339 - acc: 0.9581 - auc: 0.8606    \n",
      "Epoch 182/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1307 - acc: 0.9587 - auc: 0.8609    \n",
      "Epoch 183/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1307 - acc: 0.9588 - auc: 0.8611    \n",
      "Epoch 184/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1302 - acc: 0.9587 - auc: 0.8614    \n",
      "Epoch 185/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1317 - acc: 0.9585 - auc: 0.8617    \n",
      "Epoch 186/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1324 - acc: 0.9585 - auc: 0.8619    \n",
      "Epoch 187/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1311 - acc: 0.9588 - auc: 0.8622    \n",
      "Epoch 188/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1295 - acc: 0.9594 - auc: 0.8624    \n",
      "Epoch 189/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1305 - acc: 0.9589 - auc: 0.8627    \n",
      "Epoch 190/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1299 - acc: 0.9589 - auc: 0.8630    \n",
      "Epoch 191/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1306 - acc: 0.9587 - auc: 0.8632    \n",
      "Epoch 192/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1314 - acc: 0.9582 - auc: 0.8635    \n",
      "Epoch 193/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1315 - acc: 0.9588 - auc: 0.8637    \n",
      "Epoch 194/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1315 - acc: 0.9588 - auc: 0.8639    \n",
      "Epoch 195/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1299 - acc: 0.9589 - auc: 0.8642    \n",
      "Epoch 196/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1316 - acc: 0.9591 - auc: 0.8644    \n",
      "Epoch 197/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1294 - acc: 0.9589 - auc: 0.8646    \n",
      "Epoch 198/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1280 - acc: 0.9590 - auc: 0.8649    \n",
      "Epoch 199/200\n",
      "17563/17563 [==============================] - 12s - loss: 0.1306 - acc: 0.9585 - auc: 0.8651    \n",
      "Epoch 200/200\n",
      "17563/17563 [==============================] - 13s - loss: 0.1281 - acc: 0.9589 - auc: 0.8654    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0013238990>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=100\n",
    "epochs=200\n",
    "model.fit(inputs, y_train, batch_size = batch_size, nb_epoch=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_swp = np.swapaxes(X_test,0,1)\n",
    "inputs_test = []\n",
    "for i in range(X_test_swp.shape[0]):\n",
    "    inputs_test.append(X_test_swp[i])\n",
    "\n",
    "y_pred = model.predict(inputs_test)\n",
    "y_train_pred = model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666282971802\n",
      "0.914226964597\n"
     ]
    }
   ],
   "source": [
    "print roc_auc_score(y_test, y_pred)\n",
    "print roc_auc_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense, merge\n",
    "from keras.models import Model\n",
    "\n",
    "tweet_a = Input(shape=(140, 256))\n",
    "tweet_b = Input(shape=(140, 256))\n",
    "# this layer can take as input a matrix\n",
    "# and will return a vector of size 64\n",
    "shared_lstm = LSTM(64)\n",
    "\n",
    "# when we reuse the same layer instance\n",
    "# multiple times, the weights of the layer\n",
    "# are also being reused\n",
    "# (it is effectively *the same* layer)\n",
    "encoded_a = shared_lstm(tweet_a)\n",
    "encoded_b = shared_lstm(tweet_b)\n",
    "\n",
    "encoded = [encoded_a, encoded_b]\n",
    "\n",
    "# we can then concatenate the two vectors:\n",
    "merged_vector = merge(encoded, mode='concat', concat_axis=-1)\n",
    "\n",
    "# and add a logistic regression on top\n",
    "predictions = Dense(1, activation='sigmoid')(merged_vector)\n",
    "\n",
    "# we define a trainable model linking the\n",
    "# tweet inputs to the predictions\n",
    "model = Model(input=[tweet_a, tweet_b], output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
