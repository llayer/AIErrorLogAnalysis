{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of Higgs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/llayer/AIErrorLogAnalysis/blob/master/Higgs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPBJ_Fkqatao",
        "colab_type": "text"
      },
      "source": [
        "# Higgs ML dataset studies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYiLaejiY1wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "044bb556-d7b3-461d-fe09-b8068ef07ab6",
        "id": "7E8GpkJsZeeD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/llayer/ml_exercise"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ml_exercise' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMFxP9uzZzAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "095c1508-76eb-43bd-d675-26d4221e2897"
      },
      "source": [
        "!pip3 install scikit-optimize"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.6/dist-packages (0.7.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.1)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.17.5)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (19.12.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCPA968mZ4t8",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgl4De_IY1wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sig = pd.read_hdf('ml_exercise/higgs_signal.h5')\n",
        "bkg = pd.read_hdf('ml_exercise/higgs_bkg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp7TCQ6OY1wp",
        "colab_type": "code",
        "outputId": "d65028e2-b5b6-4060-cc7c-9557288b4007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "sig.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lepton_pT</th>\n",
              "      <th>lepton_eta</th>\n",
              "      <th>lepton_phi</th>\n",
              "      <th>missing_energy_magnitude</th>\n",
              "      <th>missing_energy_phi</th>\n",
              "      <th>jet1_pt</th>\n",
              "      <th>jet1_eta</th>\n",
              "      <th>jet1_phi</th>\n",
              "      <th>jet1_btag</th>\n",
              "      <th>jet2_pt</th>\n",
              "      <th>jet2_eta</th>\n",
              "      <th>jet2_phi</th>\n",
              "      <th>jet2_btag</th>\n",
              "      <th>jet3_pt</th>\n",
              "      <th>jet3_eta</th>\n",
              "      <th>jet3_phi</th>\n",
              "      <th>jet3_btag</th>\n",
              "      <th>jet4_pt</th>\n",
              "      <th>jet4_eta</th>\n",
              "      <th>jet4_phi</th>\n",
              "      <th>jet4_btag</th>\n",
              "      <th>m_jj</th>\n",
              "      <th>m_jjj</th>\n",
              "      <th>m_lv</th>\n",
              "      <th>m_jlv</th>\n",
              "      <th>m_bb</th>\n",
              "      <th>m_wbb</th>\n",
              "      <th>m_wwbb</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.723801</td>\n",
              "      <td>-0.914611</td>\n",
              "      <td>0.910944</td>\n",
              "      <td>1.194830</td>\n",
              "      <td>-0.448292</td>\n",
              "      <td>0.839489</td>\n",
              "      <td>-0.871428</td>\n",
              "      <td>0.587799</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.654446</td>\n",
              "      <td>1.159881</td>\n",
              "      <td>-0.725923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422018</td>\n",
              "      <td>1.636800</td>\n",
              "      <td>-0.880565</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.033994</td>\n",
              "      <td>-0.704196</td>\n",
              "      <td>-0.916982</td>\n",
              "      <td>3.101961</td>\n",
              "      <td>0.867059</td>\n",
              "      <td>1.127180</td>\n",
              "      <td>1.211664</td>\n",
              "      <td>0.695883</td>\n",
              "      <td>0.694068</td>\n",
              "      <td>0.755813</td>\n",
              "      <td>0.761658</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.974119</td>\n",
              "      <td>0.660297</td>\n",
              "      <td>-1.362428</td>\n",
              "      <td>1.234102</td>\n",
              "      <td>1.677716</td>\n",
              "      <td>1.478815</td>\n",
              "      <td>0.408940</td>\n",
              "      <td>-0.105273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.017048</td>\n",
              "      <td>-0.127190</td>\n",
              "      <td>0.363313</td>\n",
              "      <td>2.214872</td>\n",
              "      <td>0.918675</td>\n",
              "      <td>0.072083</td>\n",
              "      <td>1.162631</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.961458</td>\n",
              "      <td>0.629154</td>\n",
              "      <td>1.604089</td>\n",
              "      <td>3.101961</td>\n",
              "      <td>1.938668</td>\n",
              "      <td>1.233898</td>\n",
              "      <td>0.990063</td>\n",
              "      <td>0.524871</td>\n",
              "      <td>0.900614</td>\n",
              "      <td>0.917613</td>\n",
              "      <td>1.083369</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.946889</td>\n",
              "      <td>0.169416</td>\n",
              "      <td>1.210014</td>\n",
              "      <td>0.343294</td>\n",
              "      <td>-1.579545</td>\n",
              "      <td>0.999435</td>\n",
              "      <td>1.030804</td>\n",
              "      <td>-0.475041</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.435374</td>\n",
              "      <td>0.054457</td>\n",
              "      <td>-0.083982</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.465033</td>\n",
              "      <td>0.613681</td>\n",
              "      <td>1.492698</td>\n",
              "      <td>2.548224</td>\n",
              "      <td>1.192695</td>\n",
              "      <td>0.190256</td>\n",
              "      <td>0.558635</td>\n",
              "      <td>3.101961</td>\n",
              "      <td>0.881641</td>\n",
              "      <td>0.845381</td>\n",
              "      <td>0.997408</td>\n",
              "      <td>0.695120</td>\n",
              "      <td>0.787132</td>\n",
              "      <td>0.657668</td>\n",
              "      <td>0.721147</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.298084</td>\n",
              "      <td>-0.897079</td>\n",
              "      <td>1.224441</td>\n",
              "      <td>0.618091</td>\n",
              "      <td>0.856746</td>\n",
              "      <td>0.493122</td>\n",
              "      <td>-0.021810</td>\n",
              "      <td>-1.520042</td>\n",
              "      <td>2.173076</td>\n",
              "      <td>0.973234</td>\n",
              "      <td>0.325470</td>\n",
              "      <td>-0.250431</td>\n",
              "      <td>2.214872</td>\n",
              "      <td>0.782569</td>\n",
              "      <td>-0.841807</td>\n",
              "      <td>-0.817325</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.810789</td>\n",
              "      <td>-1.033162</td>\n",
              "      <td>0.581386</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.848238</td>\n",
              "      <td>0.925814</td>\n",
              "      <td>0.973957</td>\n",
              "      <td>0.961469</td>\n",
              "      <td>0.946147</td>\n",
              "      <td>1.028120</td>\n",
              "      <td>0.848133</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.022289</td>\n",
              "      <td>-0.481195</td>\n",
              "      <td>0.169649</td>\n",
              "      <td>1.103255</td>\n",
              "      <td>0.744424</td>\n",
              "      <td>1.648197</td>\n",
              "      <td>-0.780327</td>\n",
              "      <td>-1.484007</td>\n",
              "      <td>2.173076</td>\n",
              "      <td>0.675472</td>\n",
              "      <td>0.507117</td>\n",
              "      <td>0.395493</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.540036</td>\n",
              "      <td>0.139441</td>\n",
              "      <td>-0.549385</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.802513</td>\n",
              "      <td>-1.164748</td>\n",
              "      <td>-0.284934</td>\n",
              "      <td>1.550981</td>\n",
              "      <td>0.717778</td>\n",
              "      <td>0.752909</td>\n",
              "      <td>0.996800</td>\n",
              "      <td>1.648921</td>\n",
              "      <td>1.138676</td>\n",
              "      <td>1.118826</td>\n",
              "      <td>0.977200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   lepton_pT  lepton_eta  lepton_phi  ...     m_wbb    m_wwbb  label\n",
              "0   0.723801   -0.914611    0.910944  ...  0.755813  0.761658      0\n",
              "1   1.974119    0.660297   -1.362428  ...  0.917613  1.083369      0\n",
              "2   0.946889    0.169416    1.210014  ...  0.657668  0.721147      0\n",
              "3   1.298084   -0.897079    1.224441  ...  1.028120  0.848133      0\n",
              "4   1.022289   -0.481195    0.169649  ...  1.118826  0.977200      0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4WBvBRsY1wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.concat([sig, bkg])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnoSsoG8df2h",
        "colab_type": "text"
      },
      "source": [
        "### Split data in train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y4nYcXHde4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def prep_data(data, val_size = 0.2):\n",
        "\n",
        "    features = data.drop(['label'], axis=1)\n",
        "    labels = data[['label']].values.ravel()\n",
        "    X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=val_size, random_state=42)\n",
        "\n",
        "    return X_train, X_val, y_train, y_val\n",
        "\n",
        "X_train, X_val, y_train, y_val = prep_data(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz6Kr_wHbLCn",
        "colab_type": "text"
      },
      "source": [
        "## 2. Feature importance with XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1szgLItqcDqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "\n",
        "def get_feature_importance(X, y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.33, random_state=42)\n",
        "\n",
        "    # Early stopping\n",
        "    early_stopping_rounds = 5\n",
        "\n",
        "    # Define model\n",
        "    model_bdt = xgb.XGBClassifier(n_jobs = 4)\n",
        "\n",
        "    # Last in list is used for early stopping\n",
        "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "\n",
        "    # Fit with early stopping\n",
        "    model_bdt.fit(X_train, y_train, eval_metric=[\"logloss\"], eval_set=eval_set, \n",
        "                early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
        "    \n",
        "    plot_importance(model_bdt)\n",
        "    fscore = list(model_bdt.feature_importances_)\n",
        "    feature_importance = pd.DataFrame(list(data.drop(['label'], axis=1)))\n",
        "    feature_importance['f-score'] = fscore\n",
        "    feature_importance.columns = ['feature', 'fscore']\n",
        "    feature_importance = feature_importance.sort_values(by=['fscore'], ascending=False)\n",
        "\n",
        "    return feature_importance\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCyOAN21cgh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "fbe175b7-dc6b-46ed-a604-a3b799000acd"
      },
      "source": [
        "feature_importance = get_feature_importance(X_train, y_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE3LWERhjTMhZR2CMMSFnHYExxoTc/weTyUv6Wdu4gQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_REzjOrwdDFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e06cbd3a-f019-40de-ae1f-c91d4aa27b21"
      },
      "source": [
        "feature_importance.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>fscore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>m_bb</td>\n",
              "      <td>0.139647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>m_wbb</td>\n",
              "      <td>0.090148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>m_wwbb</td>\n",
              "      <td>0.078791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>m_jjj</td>\n",
              "      <td>0.075887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>jet1_pt</td>\n",
              "      <td>0.072598</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    feature    fscore\n",
              "25     m_bb  0.139647\n",
              "26    m_wbb  0.090148\n",
              "27   m_wwbb  0.078791\n",
              "22    m_jjj  0.075887\n",
              "5   jet1_pt  0.072598"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWiqfCYZdxai",
        "colab_type": "text"
      },
      "source": [
        "## Test algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTY8ZTRaeIbK",
        "colab_type": "text"
      },
      "source": [
        "### Set up Bayesian optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JadlZZmLd7O-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "import skopt\n",
        "from skopt.utils import use_named_args\n",
        "from skopt import gp_minimize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def fit_lreg(X_train, y_train, X_test, y_test, p):\n",
        "\n",
        "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
        "    predictions = model_bdt.clf(X_test)[:,1]\n",
        "    return roc_auc_score(y_test, predictions)\n",
        "\n",
        "\n",
        "def fit_xgboost(X_train, y_train, X_test, y_test, p):\n",
        "\n",
        "    # Early stopping\n",
        "    early_stopping_rounds = 10\n",
        "    # Define model\n",
        "    model_bdt = xgb.XGBClassifier(n_jobs = 4, n_estimators = 1000, learning_rate = p['learning_rate'],\n",
        "                            max_depth = p['max_depth'], min_child_weight = p['min_child_weight'])\n",
        "    # Last in list is used for early stopping\n",
        "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "    # Fit with early stopping\n",
        "    model_bdt.fit(X_train, y_train, eval_metric=[\"logloss\"], eval_set=eval_set, \n",
        "                    early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
        "    predictions = model_bdt.predict_proba(X_test)[:,1]\n",
        "    return roc_auc_score(y_test, predictions)\n",
        "\n",
        "def fit_keras(X_train, y_train, X_test, y_test, p):\n",
        "\n",
        "    # Early stopping\n",
        "    patience = 5\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=patience)\n",
        "    \n",
        "    # Define model\n",
        "    model = create_model(features.shape[1], p['dense_layers'], p['dense_units'], 0., \n",
        "                            #p['regulizer_value'], \n",
        "                            p['dropout_value'], \n",
        "                            p['learning_rate'])\n",
        "    \n",
        "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100,# p['batch_size'], \n",
        "                        epochs=1000, verbose=0, callbacks=[es])\n",
        "\n",
        "    predictions = model.predict(X_test)\n",
        "    return roc_auc_score(y_test, predictions)\n",
        "\n",
        "\n",
        "def optimize( algo, dimensions, initial_param, data, cv = False, kfold_splits = 5, num_calls=12, random_state = 42): \n",
        "\n",
        "    prior_values = []\n",
        "    prior_names = []\n",
        "    for var in dimensions:\n",
        "        name = var.name\n",
        "        print( name )\n",
        "        prior_names.append(name)\n",
        "        prior_values.append(initial_param[name])\n",
        "\n",
        "    global num_skopt_call\n",
        "    num_skopt_call = 0\n",
        "    #errors = []\n",
        "\n",
        "    @use_named_args(dimensions)\n",
        "    def fitness(**p): \n",
        "\n",
        "        global num_skopt_call\n",
        "\n",
        "        print('\\n \\t ::: {} SKOPT CALL ::: \\n'.format(num_skopt_call+1))\n",
        "        print(p)\n",
        "\n",
        "        reduced_feat = feature_importance.iloc[0:p['n_feat']]\n",
        "        reduced_feat = list(reduced_feat['feature'])\n",
        "        data_red = data[reduced_feat]\n",
        "        features = data_red.values\n",
        "        labels = data[['label']].values.ravel()\n",
        "\n",
        "        if cv == False:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=random_state)\n",
        "            if algo == 'xgboost':\n",
        "                score = fit_xgboost(X_train, y_train, X_test, y_test, p)\n",
        "            if algo == 'keras':\n",
        "                score = fit_keras(X_train, y_train, X_test, y_test, p)\n",
        "            print(score)\n",
        "\n",
        "        else:\n",
        "            cv_scores = []    \n",
        "            enum = enumerate(KFold(n_splits=kfold_splits, shuffle=True, random_state=random_state).split(features,labels))\n",
        "            for i,(index_train, index_valid) in enum:\n",
        "                X_train, X_test = features[ index_train ], features[ index_valid ]\n",
        "                y_train, y_test = labels[ index_train ], labels[ index_valid ]   \n",
        "                if algo == 'xgboost':\n",
        "                    score = fit_xgboost(X_train, y_train, X_test, y_test, p)\n",
        "                if algo == 'keras':\n",
        "                    score = fit_keras(X_train, y_train, X_test, y_test, p)\n",
        "                cv_scores.append(score)\n",
        "                print( cv_scores )\n",
        "            score = np.mean(cv_scores)\n",
        "            print(score)\n",
        "            print(np.std(cv_scores))\n",
        "\n",
        "        num_skopt_call += 1\n",
        "\n",
        "        return -1*score\n",
        "\n",
        "    search_result = gp_minimize( func = fitness, dimensions = dimensions,\n",
        "                                 acq_func = 'EI', # Expected Improvement\n",
        "                                 n_calls = num_calls, x0 = prior_values )\n",
        "\n",
        "    params = pd.DataFrame(search_result['x_iters'])\n",
        "    params.columns = [*prior_names]\n",
        "    params = params.rename_axis('call').reset_index()\n",
        "    scores = pd.DataFrame(search_result['func_vals'])\n",
        "    scores.columns = ['score']\n",
        "    result = pd.concat([params, scores], axis=1)\n",
        "    result = result.sort_values(by=['score'])\n",
        "    #errors_frame = pd.DataFrame(errors, columns = ['call', 'q_error', 't_error'])\n",
        "    #result = pd.merge(result, errors_frame, on=['call'])   \n",
        "    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r236T_l7d2AK",
        "colab_type": "text"
      },
      "source": [
        "### 1. XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Oz0bOrMdCs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "# Skopt dimensions\n",
        "skopt_dims = [       \n",
        "    Real(        low=1e-2, high=1,     prior='log-uniform', name='learning_rate'     ),\n",
        "    Integer(        low=2,    high=20,                         name='max_depth'     ),\n",
        "    Integer(        low=1,    high=20,                         name='min_child_weight'     ),\n",
        "    Real(        low=1e-6, high=1e-2,     prior='log-uniform', name='reg_alpha'     ),\n",
        "    Integer(     low=5,    high=27,                        name='n_feat'       )\n",
        "\n",
        "]\n",
        "\n",
        "# Initial parameters\n",
        "init_param = {'learning_rate' : 0.3, 'reg_alpha' : 1e-5, 'max_depth' : 6, 'min_child_weight' : 1, 'n_feat':12 }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUaHPgdeevWs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "0c8d5b9a-4517-4461-dc68-0cbf1f7c94a9"
      },
      "source": [
        "search_result = optimize('xgboost', skopt_dims, init_param, data, cv = True, num_calls=20, random_state = 42)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning_rate\n",
            "max_depth\n",
            "min_child_weight\n",
            "reg_alpha\n",
            "n_feat\n",
            "\n",
            " \t ::: 1 SKOPT CALL ::: \n",
            "\n",
            "{'learning_rate': 0.3, 'max_depth': 6, 'min_child_weight': 1, 'reg_alpha': 1e-05, 'n_feat': 12}\n",
            "[0.7754328578154179]\n",
            "[0.7754328578154179, 0.7919428262996222]\n",
            "[0.7754328578154179, 0.7919428262996222, 0.779414937729251]\n",
            "[0.7754328578154179, 0.7919428262996222, 0.779414937729251, 0.7957423210858326]\n",
            "[0.7754328578154179, 0.7919428262996222, 0.779414937729251, 0.7957423210858326, 0.7997038066424149]\n",
            "0.7884473499145077\n",
            "0.00941386479718343\n",
            "\n",
            " \t ::: 2 SKOPT CALL ::: \n",
            "\n",
            "{'learning_rate': 0.018860930104911692, 'max_depth': 3, 'min_child_weight': 9, 'reg_alpha': 1.68374180887052e-05, 'n_feat': 15}\n",
            "[0.7830459198942705]\n",
            "[0.7830459198942705, 0.7926927104857034]\n",
            "[0.7830459198942705, 0.7926927104857034, 0.7865555786405567]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-843146852495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgboost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskopt_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-e25da49e73cf>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(algo, dimensions, initial_param, data, cv, kfold_splits, num_calls, random_state)\u001b[0m\n\u001b[1;32m    101\u001b[0m     search_result = gp_minimize( func = fitness, dimensions = dimensions,\n\u001b[1;32m    102\u001b[0m                                  \u001b[0macq_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Expected Improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                                  n_calls = num_calls, x0 = prior_values )\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_iters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-e25da49e73cf>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(**p)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mindex_train\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mindex_valid\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'xgboost'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_xgboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'keras'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-e25da49e73cf>\u001b[0m in \u001b[0;36mfit_xgboost\u001b[0;34m(X_train, y_train, X_test, y_test, p)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Fit with early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     model_bdt.fit(X_train, y_train, eval_metric=[\"logloss\"], eval_set=eval_set, \n\u001b[0;32m---> 22\u001b[0;31m                     early_stopping_rounds=early_stopping_rounds, verbose=False)\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_bdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaC2QkDngdWI",
        "colab_type": "text"
      },
      "source": [
        "### 2. Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMJ02LakiRc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, Reshape\n",
        "\n",
        "def create_model( n_features, dense_layers, dense_units, regulizer_value, dropout_value, learning_rate ):\n",
        "\n",
        "    m_input = Input(shape = (n_features, ))\n",
        "    m = m_input\n",
        "    \n",
        "    for _ in range(dense_layers):\n",
        "        m = Dense( units=dense_units, activation='relu', \n",
        "                   kernel_initializer='lecun_normal',\n",
        "                   kernel_regularizer=keras.regularizers.l2(regulizer_value) )(m)\n",
        "        m = Dropout(dropout_value)(m)\n",
        "\n",
        "    m_output = Dense( units=1, activation='sigmoid', \n",
        "                      kernel_initializer='lecun_normal',\n",
        "                      kernel_regularizer=keras.regularizers.l2(regulizer_value) )(m)\n",
        "\n",
        "    model = keras.models.Model(inputs=m_input, outputs=m_output)\n",
        "    model.compile( loss = 'binary_crossentropy',\n",
        "                        optimizer = keras.optimizers.Adam(lr=learning_rate) )\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqB7c3v4ipkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dimensions = [\n",
        "    Integer(     low=1,    high=5,                        name='dense_layers'      ),\n",
        "    #Integer(     low=100,    high=1000,                    name='batch_size'      ),\n",
        "    Integer(     low=5,    high=200,                        name='dense_units'       ),\n",
        "    #Real(        low=1e-3, high=0.9,  prior=\"log-uniform\", name='regulizer_value'   ),\n",
        "    Real(        low=1e-3, high=0.5,   prior=\"log-uniform\",                    name='dropout_value'     ),\n",
        "    Real(        low=1e-4, high=1e-1, prior='log-uniform', name='learning_rate'     ),\n",
        "    Integer(     low=5,    high=27,                        name='n_feat'       )\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "# Initial parameters\n",
        "init_param = {'learning_rate' : 1e-2, 'dense_layers' : 3, 'regulizer_value' : 1e-2, 'dropout_value': 0.02, \n",
        "             'dense_units' : 20, 'batch_size' : 100, 'n_feat': 20}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7oIVki7gT9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f01aaba-290b-4c5d-a476-b1678c0353b4"
      },
      "source": [
        "search_result = optimize('keras', dimensions, init_param, data, \n",
        "                             num_calls=100, random_seed = 1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dense_layers\n",
            "dense_units\n",
            "dropout_value\n",
            "learning_rate\n",
            "n_feat\n",
            "\n",
            " \t ::: 1 SKOPT CALL ::: \n",
            "\n",
            "{'dense_layers': 3, 'dense_units': 20, 'dropout_value': 0.02, 'learning_rate': 0.01, 'n_feat': 20}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "0.7508112593510607\n",
            "0.732589679331526\n",
            "\n",
            " \t ::: 2 SKOPT CALL ::: \n",
            "\n",
            "{'dense_layers': 3, 'dense_units': 118, 'dropout_value': 0.17048057837730596, 'learning_rate': 0.015821751648560967, 'n_feat': 25}\n",
            "0.7351910179471172\n",
            "0.7067717534476262\n",
            "\n",
            " \t ::: 3 SKOPT CALL ::: \n",
            "\n",
            "{'dense_layers': 2, 'dense_units': 28, 'dropout_value': 0.002301067637042528, 'learning_rate': 0.01276450744457826, 'n_feat': 18}\n",
            "0.7654692973864804\n",
            "0.7398850085667772\n",
            "\n",
            " \t ::: 4 SKOPT CALL ::: \n",
            "\n",
            "{'dense_layers': 4, 'dense_units': 23, 'dropout_value': 0.010938015249127688, 'learning_rate': 0.00010303403289138984, 'n_feat': 24}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-cb6409180785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m search_result = optimize('keras', dimensions, init_param, data, \n\u001b[0;32m----> 2\u001b[0;31m                              num_calls=100, random_seed = 1)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-ee468d61ffcf>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(algo, dimensions, initial_param, data, num_calls, random_seed)\u001b[0m\n\u001b[1;32m     84\u001b[0m     search_result = gp_minimize( func = fitness, dimensions = dimensions,\n\u001b[1;32m     85\u001b[0m                                  \u001b[0macq_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Expected Improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                                  n_calls = num_calls, x0 = prior_values )\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_iters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ee468d61ffcf>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(**p)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100,# p['batch_size'], \n\u001b[0;32m---> 71\u001b[0;31m                                 epochs=1000, verbose=0, callbacks=[es])\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cduM1_sxcsQP",
        "colab_type": "text"
      },
      "source": [
        "## Genetic Algorithm for feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ycfTELvY1w9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_samples = features.shape[0]\n",
        "num_feature_elements = features.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXpnXamrY1xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sol_per_pop = 12 # Population size.\n",
        "num_parents_mating = 6 # Number of parents inside the mating pool.\n",
        "num_mutations = 3 # Number of elements to mutate.\n",
        "\n",
        "# Defining the population shape.\n",
        "pop_shape = (sol_per_pop, num_feature_elements)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd5XxoAiY1xF",
        "colab_type": "code",
        "outputId": "17b2d372-e843-40b0-ca13-42d9db3ce4d4",
        "colab": {}
      },
      "source": [
        "# Creating the initial population.\n",
        "new_population = np.random.randint(low=0, high=2, size=pop_shape)\n",
        "print(new_population.shape)\n",
        "\n",
        "best_outputs = []\n",
        "num_generations = 100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Out3kF2Y1xI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ga"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOj8smL2Y1xP",
        "colab_type": "code",
        "outputId": "8d7c37b8-cd67-4ebb-f24a-a08c8e0ec9ea",
        "colab": {}
      },
      "source": [
        "import importlib\n",
        "importlib.reload(ga)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'ga' from '/eos/home-l/llayer/Higgs/ga.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eUeEDUgRY1xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for generation in range(num_generations):\n",
        "    print(\"Generation : \", generation)\n",
        "    \n",
        "    # Measuring the fitness of each chromosome in the population.\n",
        "    fitness = ga.cal_pop_fitness(new_population, features, labels)\n",
        "\n",
        "    print( fitness )\n",
        "    \n",
        "    best_outputs.append(np.max(fitness))\n",
        "    # The best result in the current iteration.\n",
        "    print(\"Best result : \", best_outputs[-1])\n",
        "\n",
        "    # Selecting the best parents in the population for mating.\n",
        "    parents = ga.select_mating_pool(new_population, fitness, num_parents_mating)\n",
        "\n",
        "    # Generating next generation using crossover.\n",
        "    offspring_crossover = ga.crossover(parents, offspring_size=(pop_shape[0]-parents.shape[0], num_feature_elements))\n",
        "\n",
        "    # Adding some variations to the offspring using mutation.\n",
        "    offspring_mutation = ga.mutation(offspring_crossover, num_mutations=num_mutations)\n",
        "\n",
        "    # Creating the new population based on the parents and offspring.\n",
        "    new_population[0:parents.shape[0], :] = parents\n",
        "    new_population[parents.shape[0]:, :] = offspring_mutation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFyEdZJAY1xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1lCk6djY1xY",
        "colab_type": "code",
        "outputId": "06179466-334e-46a6-d821-b80af41eb9fa",
        "colab": {}
      },
      "source": [
        "\n",
        "# Getting the best solution after iterating finishing all generations.\n",
        "# At first, the fitness is calculated for each solution in the final generation.\n",
        "fitness = ga.cal_pop_fitness(new_population, features, labels)\n",
        "# Then return the index of that solution corresponding to the best fitness.\n",
        "best_match_idx = np.where(fitness == np.max(fitness))[0]\n",
        "best_match_idx = best_match_idx[0]\n",
        "\n",
        "best_solution = new_population[best_match_idx, :]\n",
        "best_solution_indices = np.where(best_solution == 1)[0]\n",
        "best_solution_num_elements = best_solution_indices.shape[0]\n",
        "best_solution_fitness = fitness[best_match_idx]\n",
        "\n",
        "print(\"best_match_idx : \", best_match_idx)\n",
        "print(\"best_solution : \", best_solution)\n",
        "print(\"Selected indices : \", best_solution_indices)\n",
        "print(\"Number of selected elements : \", best_solution_num_elements)\n",
        "print(\"Best solution fitness : \", best_solution_fitness)\n",
        "\n",
        "plt.plot(best_outputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7822324019697021\n",
            "0.7819253075467076\n",
            "0.7818933032385696\n",
            "0.7818724568169131\n",
            "0.7818649263914688\n",
            "0.7818597836618972\n",
            "0.7717151526577948\n",
            "0.7714571437518729\n",
            "0.7712103386496606\n",
            "0.7722144565985307\n",
            "0.7714556284833383\n",
            "0.7720901127442441\n",
            "best_match_idx :  0\n",
            "best_solution :  [1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "Selected indices :  [ 0  2  3  4  5  8  9 12 13 14 15 16 18 19 20 21 22 23 24 25 26 27]\n",
            "Number of selected elements :  22\n",
            "Best solution fitness :  0.7822324019697021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f74e890a518>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tphFZpHeY1xb",
        "colab_type": "code",
        "outputId": "b2451c9e-42e9-43f5-8282-1918722a9853",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import sklearn.svm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
        "\n",
        "\"\"\"\n",
        "SV_classifier = sklearn.svm.SVC(gamma='scale')\n",
        "SV_classifier.fit(X=X_train, y=y_train)\n",
        "\n",
        "predictions = SV_classifier.decision_function(X_test)#.predict(X_test)\n",
        "score = roc_auc_score(y_test, predictions) # classification_accuracy(y_test, predictions)\n",
        "print(score)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nSV_classifier = sklearn.svm.SVC(gamma='scale')\\nSV_classifier.fit(X=X_train, y=y_train)\\n\\npredictions = SV_classifier.decision_function(X_test)#.predict(X_test)\\nscore = roc_auc_score(y_test, predictions) # classification_accuracy(y_test, predictions)\\nprint(score)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOdN441PY1xr",
        "colab_type": "code",
        "outputId": "6e5fd833-728c-4a73-dfff-49aae07f618a",
        "colab": {}
      },
      "source": [
        "predictions = model_bdt.predict_proba(X_test)[:,1]\n",
        "score = roc_auc_score(y_test, predictions)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7805039397441069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtaCUF7uY1yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fitness = pd.DataFrame(best_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwycEN_sY1yC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fitness.to_hdf('xgb_sol_12_parents_6_mutations_3.h5', 'frame')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsIUPtMRY1yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSW4s8suY1yY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qDYdijsY1yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWHeuKCtY1yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}